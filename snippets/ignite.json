{
    "Mnist Example": {
        "prefix": "ignite:examples:mnist",
        "description": "Mnist code example",
        "body": [
            "from argparse import ArgumentParser",
            "",
            "from torch import nn",
            "from torch.optim import SGD",
            "from torch.utils.data import DataLoader",
            "import torch",
            "import torch.nn.functional as F",
            "from torchvision.transforms import Compose, ToTensor, Normalize",
            "from torchvision.datasets import MNIST",
            "",
            "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator",
            "from ignite.metrics import Accuracy, Loss",
            "",
            "from tqdm import tqdm",
            "",
            "",
            "class Net(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Net, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)",
            "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)",
            "\t\tself.conv2_drop = nn.Dropout2d()",
            "\t\tself.fc1 = nn.Linear(320, 50)",
            "\t\tself.fc2 = nn.Linear(50, 10)",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(F.max_pool2d(self.conv1(x), 2))",
            "\t\tx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))",
            "\t\tx = x.view(-1, 320)",
            "\t\tx = F.relu(self.fc1(x))",
            "\t\tx = F.dropout(x, training=self.training)",
            "\t\tx = self.fc2(x)",
            "\t\treturn F.log_softmax(x, dim=-1)",
            "",
            "",
            "def get_data_loaders(train_batch_size, val_batch_size):",
            "\tdata_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])",
            "",
            "\ttrain_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),",
            "\t\t\t\t\t\t\t  batch_size=train_batch_size, shuffle=True)",
            "",
            "\tval_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),",
            "\t\t\t\t\t\t\tbatch_size=val_batch_size, shuffle=False)",
            "\treturn train_loader, val_loader",
            "",
            "",
            "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):",
            "\ttrain_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)",
            "\tmodel = Net()",
            "\tdevice = 'cpu'",
            "",
            "\tif torch.cuda.is_available():",
            "\t\tdevice = 'cuda'",
            "",
            "\toptimizer = SGD(model.parameters(), lr=lr, momentum=momentum)",
            "\ttrainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)",
            "\tevaluator = create_supervised_evaluator(model,",
            "\t\t\t\t\t\t\t\t            metrics={'accuracy': Accuracy(),",
            "\t\t\t\t\t\t\t\t                     'nll': Loss(F.nll_loss)},",
            "\t\t\t\t\t\t\t\t            device=device)",
            "",
            "\tdesc = \"ITERATION - loss: {:.2f}\"",
            "\tpbar = tqdm(",
            "\t\tinitial=0, leave=False, total=len(train_loader),",
            "\t\tdesc=desc.format(0)",
            "\t)",
            "",
            "\t@trainer.on(Events.ITERATION_COMPLETED)",
            "\tdef log_training_loss(engine):",
            "\t\titer = (engine.state.iteration - 1) % len(train_loader) + 1",
            "",
            "\t\tif iter % log_interval == 0:",
            "\t\t\tpbar.desc = desc.format(engine.state.output)",
            "\t\t\tpbar.update(log_interval)",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_training_results(engine):",
            "\t\tpbar.refresh()",
            "\t\tevaluator.run(train_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\ttqdm.write(",
            "\t\t\t\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t.format(engine.state.epoch, avg_accuracy, avg_nll)",
            "\t\t)",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_validation_results(engine):",
            "\t\tevaluator.run(val_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\ttqdm.write(",
            "\t\t\t\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t.format(engine.state.epoch, avg_accuracy, avg_nll))",
            "",
            "\t\tpbar.n = pbar.last_print_n = 0",
            "",
            "\ttrainer.run(train_loader, max_epochs=epochs)",
            "\tpbar.close()",
            "",
            "",
            "if __name__ == \"__main__\":",
            "\tparser = ArgumentParser()",
            "\tparser.add_argument('--batch_size', type=int, default=64,",
            "\t\t\t\t\t\thelp='input batch size for training (default: 64)')",
            "\tparser.add_argument('--val_batch_size', type=int, default=1000,",
            "\t\t\t\t\t\thelp='input batch size for validation (default: 1000)')",
            "\tparser.add_argument('--epochs', type=int, default=10,",
            "\t\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "\tparser.add_argument('--lr', type=float, default=0.01,",
            "\t\t\t\t\t\thelp='learning rate (default: 0.01)')",
            "\tparser.add_argument('--momentum', type=float, default=0.5,",
            "\t\t\t\t\t\thelp='SGD momentum (default: 0.5)')",
            "\tparser.add_argument('--log_interval', type=int, default=10,",
            "\t\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "",
            "\targs = parser.parse_args()",
            "",
            "\trun(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)"
        ]
    },
    "Mnist with TensorBoardX Example": {
        "prefix": "ignite:examples:mnist-tbx",
        "description": "Mnist with TensorBoardX code example",
        "body": [
            "\"\"\"",
            " MNIST example with training and validation monitoring using TensorboardX and Tensorboard.",
            " Requirements:",
            "\tTensorboardX (https://github.com/lanpa/tensorboard-pytorch): `pip install tensorboardX`",
            "\tTensorboard: `pip install tensorflow` (or just install tensorboard without the rest of tensorflow)",
            " Usage:",
            "\tStart tensorboard:",
            "\t```bash",
            "\ttensorboard --logdir=/tmp/tensorboard_logs/",
            "\t```",
            "\tRun the example:",
            "\t```bash",
            "\tpython mnist_with_tensorboardx.py --log_dir=/tmp/tensorboard_logs",
            "\t```",
            "\"\"\"",
            "",
            "from __future__ import print_function",
            "from argparse import ArgumentParser",
            "import torch",
            "from torch.utils.data import DataLoader",
            "from torch import nn",
            "import torch.nn.functional as F",
            "from torch.optim import SGD",
            "from torchvision.datasets import MNIST",
            "from torchvision.transforms import Compose, ToTensor, Normalize",
            "",
            "try:",
            "\tfrom tensorboardX import SummaryWriter",
            "except ImportError:",
            "\traise RuntimeError(\"No tensorboardX package is found. Please install with the command: \\npip install tensorboardX\")",
            "",
            "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator",
            "from ignite.metrics import Accuracy, Loss",
            "",
            "",
            "class Net(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Net, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)",
            "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)",
            "\t\tself.conv2_drop = nn.Dropout2d()",
            "\t\tself.fc1 = nn.Linear(320, 50)",
            "\t\tself.fc2 = nn.Linear(50, 10)",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(F.max_pool2d(self.conv1(x), 2))",
            "\t\tx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))",
            "\t\tx = x.view(-1, 320)",
            "\t\tx = F.relu(self.fc1(x))",
            "\t\tx = F.dropout(x, training=self.training)",
            "\t\tx = self.fc2(x)",
            "\t\treturn F.log_softmax(x, dim=-1)",
            "",
            "",
            "def get_data_loaders(train_batch_size, val_batch_size):",
            "\tdata_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])",
            "",
            "\ttrain_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),",
            "\t\t\t\t\t\t\t  batch_size=train_batch_size, shuffle=True)",
            "",
            "\tval_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),",
            "\t\t\t\t\t\t\tbatch_size=val_batch_size, shuffle=False)",
            "\treturn train_loader, val_loader",
            "",
            "",
            "def create_summary_writer(model, data_loader, log_dir):",
            "\twriter = SummaryWriter(log_dir=log_dir)",
            "\tdata_loader_iter = iter(data_loader)",
            "\tx, y = next(data_loader_iter)",
            "\ttry:",
            "\t\twriter.add_graph(model, x)",
            "\texcept Exception as e:",
            "\t\tprint(\"Failed to save model graph: {}\".format(e))",
            "\treturn writer",
            "",
            "",
            "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval, log_dir):",
            "\ttrain_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)",
            "\tmodel = Net()",
            "\twriter = create_summary_writer(model, train_loader, log_dir)",
            "\tdevice = 'cpu'",
            "",
            "\tif torch.cuda.is_available():",
            "\t\tdevice = 'cuda'",
            "",
            "\toptimizer = SGD(model.parameters(), lr=lr, momentum=momentum)",
            "\ttrainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)",
            "\tevaluator = create_supervised_evaluator(model,",
            "\t\t\t\t\t\t\t\t            metrics={'accuracy': Accuracy(),",
            "\t\t\t\t\t\t\t\t                     'nll': Loss(F.nll_loss)},",
            "\t\t\t\t\t\t\t\t            device=device)",
            "",
            "\t@trainer.on(Events.ITERATION_COMPLETED)",
            "\tdef log_training_loss(engine):",
            "\t\titer = (engine.state.iteration - 1) % len(train_loader) + 1",
            "\t\tif iter % log_interval == 0:",
            "\t\t\tprint(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"",
            "\t\t\t\t  \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))",
            "\t\t\twriter.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_training_results(engine):",
            "\t\tevaluator.run(train_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\tprint(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t  .format(engine.state.epoch, avg_accuracy, avg_nll))",
            "\t\twriter.add_scalar(\"training/avg_loss\", avg_nll, engine.state.epoch)",
            "\t\twriter.add_scalar(\"training/avg_accuracy\", avg_accuracy, engine.state.epoch)",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_validation_results(engine):",
            "\t\tevaluator.run(val_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\tprint(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t  .format(engine.state.epoch, avg_accuracy, avg_nll))",
            "\t\twriter.add_scalar(\"valdation/avg_loss\", avg_nll, engine.state.epoch)",
            "\t\twriter.add_scalar(\"valdation/avg_accuracy\", avg_accuracy, engine.state.epoch)",
            "",
            "\t# kick everything off",
            "\ttrainer.run(train_loader, max_epochs=epochs)",
            "",
            "\twriter.close()",
            "",
            "",
            "if __name__ == \"__main__\":",
            "\tparser = ArgumentParser()",
            "\tparser.add_argument('--batch_size', type=int, default=64,",
            "\t\t\t\t\t\thelp='input batch size for training (default: 64)')",
            "\tparser.add_argument('--val_batch_size', type=int, default=1000,",
            "\t\t\t\t\t\thelp='input batch size for validation (default: 1000)')",
            "\tparser.add_argument('--epochs', type=int, default=10,",
            "\t\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "\tparser.add_argument('--lr', type=float, default=0.01,",
            "\t\t\t\t\t\thelp='learning rate (default: 0.01)')",
            "\tparser.add_argument('--momentum', type=float, default=0.5,",
            "\t\t\t\t\t\thelp='SGD momentum (default: 0.5)')",
            "\tparser.add_argument('--log_interval', type=int, default=10,",
            "\t\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "\tparser.add_argument(\"--log_dir\", type=str, default=\"tensorboard_logs\",",
            "\t\t\t\t\t\thelp=\"log directory for Tensorboard log output\")",
            "",
            "\targs = parser.parse_args()",
            "",
            "\trun(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum,",
            "\t\targs.log_interval, args.log_dir)"
        ]
    },
    "Mnist with Visdom Example": {
        "prefix": "ignite:examples:mnist-visdom",
        "description": "Mnist with Visdom code example",
        "body": [
            "from __future__ import print_function",
            "from argparse import ArgumentParser",
            "",
            "import torch",
            "from torch.utils.data import DataLoader",
            "from torch import nn",
            "import torch.nn.functional as F",
            "from torch.optim import SGD",
            "from torchvision.datasets import MNIST",
            "from torchvision.transforms import Compose, ToTensor, Normalize",
            "import numpy as np",
            "try:",
            "\timport visdom",
            "except ImportError:",
            "\traise RuntimeError(\"No visdom package is found. Please install it with command: \\n pip install visdom\")",
            "",
            "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator",
            "from ignite.metrics import Accuracy, Loss",
            "",
            "",
            "class Net(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Net, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)",
            "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)",
            "\t\tself.conv2_drop = nn.Dropout2d()",
            "\t\tself.fc1 = nn.Linear(320, 50)",
            "\t\tself.fc2 = nn.Linear(50, 10)",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(F.max_pool2d(self.conv1(x), 2))",
            "\t\tx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))",
            "\t\tx = x.view(-1, 320)",
            "\t\tx = F.relu(self.fc1(x))",
            "\t\tx = F.dropout(x, training=self.training)",
            "\t\tx = self.fc2(x)",
            "\t\treturn F.log_softmax(x, dim=-1)",
            "",
            "",
            "def get_data_loaders(train_batch_size, val_batch_size):",
            "\tdata_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])",
            "",
            "\ttrain_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),",
            "\t\t\t\t\t\t\t  batch_size=train_batch_size, shuffle=True)",
            "",
            "\tval_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),",
            "\t\t\t\t\t\t\tbatch_size=val_batch_size, shuffle=False)",
            "\treturn train_loader, val_loader",
            "",
            "",
            "def create_plot_window(vis, xlabel, ylabel, title):",
            "\treturn vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))",
            "",
            "",
            "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):",
            "\tvis = visdom.Visdom()",
            "",
            "\t# if not vis.check_connection():",
            "\t#     raise RuntimeError(\"Visdom server not running. Please run python -m visdom.server\")",
            "",
            "\ttrain_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)",
            "\tmodel = Net()",
            "\tdevice = 'cpu'",
            "",
            "\tif torch.cuda.is_available():",
            "\t\tdevice = 'cuda'",
            "",
            "\toptimizer = SGD(model.parameters(), lr=lr, momentum=momentum)",
            "\ttrainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)",
            "\tevaluator = create_supervised_evaluator(model,",
            "\t\t\t\t\t\t\t\t            metrics={'accuracy': Accuracy(),",
            "\t\t\t\t\t\t\t\t                     'nll': Loss(F.nll_loss)},",
            "\t\t\t\t\t\t\t\t            device=device)",
            "",
            "\ttrain_loss_window = create_plot_window(vis, '#Iterations', 'Loss', 'Training Loss')",
            "\ttrain_avg_loss_window = create_plot_window(vis, '#Iterations', 'Loss', 'Training Average Loss')",
            "\ttrain_avg_accuracy_window = create_plot_window(vis, '#Iterations', 'Accuracy', 'Training Average Accuracy')",
            "\tval_avg_loss_window = create_plot_window(vis, '#Epochs', 'Loss', 'Validation Average Loss')",
            "\tval_avg_accuracy_window = create_plot_window(vis, '#Epochs', 'Accuracy', 'Validation Average Accuracy')",
            "",
            "\t@trainer.on(Events.ITERATION_COMPLETED)",
            "\tdef log_training_loss(engine):",
            "\t\titer = (engine.state.iteration - 1) % len(train_loader) + 1",
            "\t\tif iter % log_interval == 0:",
            "\t\t\tprint(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"",
            "\t\t\t\t  \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))",
            "\t\t\tvis.line(X=np.array([engine.state.iteration]),",
            "\t\t\t\t\t Y=np.array([engine.state.output]),",
            "\t\t\t\t\t update='append', win=train_loss_window)",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_training_results(engine):",
            "\t\tevaluator.run(train_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\tprint(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t  .format(engine.state.epoch, avg_accuracy, avg_nll))",
            "\t\tvis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]),",
            "\t\t\t\t win=train_avg_accuracy_window, update='append')",
            "\t\tvis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]),",
            "\t\t\t\t win=train_avg_loss_window, update='append')",
            "",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef log_validation_results(engine):",
            "\t\tevaluator.run(val_loader)",
            "\t\tmetrics = evaluator.state.metrics",
            "\t\tavg_accuracy = metrics['accuracy']",
            "\t\tavg_nll = metrics['nll']",
            "\t\tprint(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"",
            "\t\t\t  .format(engine.state.epoch, avg_accuracy, avg_nll))",
            "\t\tvis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]),",
            "\t\t\t\t win=val_avg_accuracy_window, update='append')",
            "\t\tvis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]),",
            "\t\t\t\t win=val_avg_loss_window, update='append')",
            "",
            "\t# kick everything off",
            "\ttrainer.run(train_loader, max_epochs=epochs)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "\tparser = ArgumentParser()",
            "\tparser.add_argument('--batch_size', type=int, default=64,",
            "\t\t\t\t\t\thelp='input batch size for training (default: 64)')",
            "\tparser.add_argument('--val_batch_size', type=int, default=1000,",
            "\t\t\t\t\t\thelp='input batch size for validation (default: 1000)')",
            "\tparser.add_argument('--epochs', type=int, default=10,",
            "\t\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "\tparser.add_argument('--lr', type=float, default=0.01,",
            "\t\t\t\t\t\thelp='learning rate (default: 0.01)')",
            "\tparser.add_argument('--momentum', type=float, default=0.5,",
            "\t\t\t\t\t\thelp='SGD momentum (default: 0.5)')",
            "\tparser.add_argument('--log_interval', type=int, default=10,",
            "\t\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "\tparser.add_argument(\"--log_file\", type=str, default=None, help=\"log file to log output to\")",
            "",
            "\targs = parser.parse_args()",
            "",
            "\trun(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)"
        ]
    },
    "DCGAN Example": {
        "prefix": "ignite:examples:dcgan",
        "description": "DCGAN code example",
        "body": [
            "from __future__ import print_function",
            "",
            "import argparse",
            "import os",
            "import random",
            "import warnings",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.optim as optim",
            "import torch.utils.data as data",
            "",
            "from ignite.contrib.handlers import ProgressBar",
            "from ignite.engine import Engine, Events",
            "from ignite.handlers import ModelCheckpoint, Timer",
            "from ignite.metrics import RunningAverage",
            "",
            "try:",
            "\timport torchvision.datasets as dset",
            "\timport torchvision.transforms as transforms",
            "\timport torchvision.utils as vutils",
            "",
            "except ImportError:",
            "\traise ImportError(\"Please install torchvision to run this example, for example \"",
            "\t\t\t\t\t  \"via conda by running 'conda install -c pytorch torchvision'. \")",
            "",
            "",
            "PRINT_FREQ = 100",
            "FAKE_IMG_FNAME = 'fake_sample_epoch_{:04d}.png'",
            "REAL_IMG_FNAME = 'real_sample_epoch_{:04d}.png'",
            "LOGS_FNAME = 'logs.tsv'",
            "PLOT_FNAME = 'plot.svg'",
            "SAMPLES_FNAME = 'samples.svg'",
            "CKPT_PREFIX = 'networks'",
            "",
            "",
            "class Net(nn.Module):",
            "\t\"\"\" A base class for both generator and the discriminator.",
            "\tProvides a common weight initialization scheme.",
            "",
            "\t\"\"\"",
            "",
            "\tdef weights_init(self):",
            "\t\tfor m in self.modules():",
            "\t\t\tclassname = m.__class__.__name__",
            "",
            "\t\t\tif 'Conv' in classname:",
            "\t\t\t\tm.weight.data.normal_(0.0, 0.02)",
            "",
            "\t\t\telif 'BatchNorm' in classname:",
            "\t\t\t\tm.weight.data.normal_(1.0, 0.02)",
            "\t\t\t\tm.bias.data.fill_(0)",
            "",
            "\tdef forward(self, x):",
            "\t\treturn x",
            "",
            "",
            "class Generator(Net):",
            "\t\"\"\" Generator network.",
            "",
            "\tArgs:",
            "\t\tnf (int): Number of filters in the second-to-last deconv layer",
            "\t\"\"\"",
            "",
            "\tdef __init__(self, z_dim, nf):",
            "\t\tsuper(Generator, self).__init__()",
            "",
            "\t\tself.net = nn.Sequential(",
            "",
            "\t\t\t# input is Z, going into a convolution",
            "\t\t\tnn.ConvTranspose2d(in_channels=z_dim, out_channels=nf * 8, kernel_size=4, stride=1, padding=0, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 8),",
            "\t\t\tnn.ReLU(inplace=True),",
            "",
            "\t\t\t# state size. (nf*8) x 4 x 4",
            "\t\t\tnn.ConvTranspose2d(in_channels=nf * 8, out_channels=nf * 4, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 4),",
            "\t\t\tnn.ReLU(inplace=True),",
            "",
            "\t\t\t# state size. (nf*4) x 8 x 8",
            "\t\t\tnn.ConvTranspose2d(in_channels=nf * 4, out_channels=nf * 2, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 2),",
            "\t\t\tnn.ReLU(inplace=True),",
            "",
            "\t\t\t# state size. (nf*2) x 16 x 16",
            "\t\t\tnn.ConvTranspose2d(in_channels=nf * 2, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf),",
            "\t\t\tnn.ReLU(inplace=True),",
            "",
            "\t\t\t# state size. (nf) x 32 x 32",
            "\t\t\tnn.ConvTranspose2d(in_channels=nf, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.Tanh()",
            "",
            "\t\t\t# state size. (nc) x 64 x 64",
            "\t\t)",
            "",
            "\t\tself.weights_init()",
            "",
            "\tdef forward(self, x):",
            "\t\treturn self.net(x)",
            "",
            "",
            "class Discriminator(Net):",
            "\t\"\"\" Discriminator network.",
            "",
            "\tArgs:",
            "\t\tnf (int): Number of filters in the first conv layer.",
            "\t\"\"\"",
            "",
            "\tdef __init__(self, nf):",
            "\t\tsuper(Discriminator, self).__init__()",
            "",
            "\t\tself.net = nn.Sequential(",
            "",
            "\t\t\t# input is (nc) x 64 x 64",
            "\t\t\tnn.Conv2d(in_channels=3, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "",
            "\t\t\t# state size. (nf) x 32 x 32",
            "\t\t\tnn.Conv2d(in_channels=nf, out_channels=nf * 2, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 2),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "",
            "\t\t\t# state size. (nf*2) x 16 x 16",
            "\t\t\tnn.Conv2d(in_channels=nf * 2, out_channels=nf * 4, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 4),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "",
            "\t\t\t# state size. (nf*4) x 8 x 8",
            "\t\t\tnn.Conv2d(in_channels=nf * 4, out_channels=nf * 8, kernel_size=4, stride=2, padding=1, bias=False),",
            "\t\t\tnn.BatchNorm2d(nf * 8),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "",
            "\t\t\t# state size. (nf*8) x 4 x 4",
            "\t\t\tnn.Conv2d(in_channels=nf * 8, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),",
            "\t\t\tnn.Sigmoid()",
            "\t\t)",
            "",
            "\t\tself.weights_init()",
            "",
            "\tdef forward(self, x):",
            "\t\toutput = self.net(x)",
            "\t\treturn output.view(-1, 1).squeeze(1)",
            "",
            "",
            "def check_manual_seed(seed):",
            "\t\"\"\" If manual seed is not specified, choose a random one and communicate it to the user.",
            "",
            "\t\"\"\"",
            "",
            "\tseed = seed or random.randint(1, 10000)",
            "\trandom.seed(seed)",
            "\ttorch.manual_seed(seed)",
            "",
            "\tprint('Using manual seed: {seed}'.format(seed=seed))",
            "",
            "",
            "def check_dataset(dataset, dataroot):",
            "\t\"\"\"",
            "",
            "\tArgs:",
            "\t\tdataset (str): Name of the dataset to use. See CLI help for details",
            "\t\tdataroot (str): root directory where the dataset will be stored.",
            "",
            "\tReturns:",
            "\t\tdataset (data.Dataset): torchvision Dataset object",
            "",
            "\t\"\"\"",
            "\tto_rgb = transforms.Lambda(lambda img: img.convert('RGB'))",
            "\tresize = transforms.Resize(64)",
            "\tcrop = transforms.CenterCrop(64)",
            "\tto_tensor = transforms.ToTensor()",
            "\tnormalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))",
            "",
            "\tif dataset in {'imagenet', 'folder', 'lfw'}:",
            "\t\tdataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([resize,",
            "\t\t\t\t\t\t\t\t                                                crop,",
            "\t\t\t\t\t\t\t\t                                                to_tensor,",
            "\t\t\t\t\t\t\t\t                                                normalize]))",
            "",
            "\telif dataset == 'lsun':",
            "\t\tdataset = dset.LSUN(root=dataroot, classes=['bedroom_train'], transform=transforms.Compose([resize,",
            "\t\t\t\t\t\t\t\t                                                                    crop,",
            "\t\t\t\t\t\t\t\t                                                                    to_tensor,",
            "\t\t\t\t\t\t\t\t                                                                    normalize]))",
            "",
            "\telif dataset == 'cifar10':",
            "\t\tdataset = dset.CIFAR10(root=dataroot, download=True, transform=transforms.Compose([resize,",
            "\t\t\t\t\t\t\t\t                                                           to_tensor,",
            "\t\t\t\t\t\t\t\t                                                           normalize]))",
            "",
            "\telif dataset == 'mnist':",
            "\t\tdataset = dset.MNIST(root=dataroot, download=True, transform=transforms.Compose([to_rgb,",
            "\t\t\t\t\t\t\t\t                                                         resize,",
            "\t\t\t\t\t\t\t\t                                                         to_tensor,",
            "\t\t\t\t\t\t\t\t                                                         normalize]))",
            "",
            "\telif dataset == 'fake':",
            "\t\tdataset = dset.FakeData(size=256, image_size=(3, 64, 64), transform=to_tensor)",
            "",
            "\telse:",
            "\t\traise RuntimeError(\"Invalid dataset name: {}\".format(dataset))",
            "",
            "\treturn dataset",
            "",
            "",
            "def main(dataset, dataroot,",
            "\t\t z_dim, g_filters, d_filters,",
            "\t\t batch_size, epochs,",
            "\t\t learning_rate, beta_1,",
            "\t\t saved_G, saved_D,",
            "\t\t seed,",
            "\t\t n_workers, device,",
            "\t\t alpha, output_dir):",
            "",
            "\t# seed",
            "\tcheck_manual_seed(seed)",
            "",
            "\t# netowrks",
            "\tnetG = Generator(z_dim, g_filters).to(device)",
            "\tnetD = Discriminator(d_filters).to(device)",
            "",
            "\t# criterion",
            "\tbce = nn.BCELoss()",
            "",
            "\t# optimizers",
            "\toptimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta_1, 0.999))",
            "\toptimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta_1, 0.999))",
            "",
            "\t# data",
            "\tdataset = check_dataset(dataset, dataroot)",
            "\tloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers, drop_last=True)",
            "",
            "\t# load pre-trained models",
            "\tif saved_G:",
            "\t\tnetG.load_state_dict(torch.load(saved_G))",
            "",
            "\tif saved_D:",
            "\t\tnetD.load_state_dict(torch.load(saved_D))",
            "",
            "\t# misc",
            "\treal_labels = torch.ones(batch_size, device=device)",
            "\tfake_labels = torch.zeros(batch_size, device=device)",
            "\tfixed_noise = torch.randn(batch_size, z_dim, 1, 1, device=device)",
            "",
            "\tdef get_noise():",
            "\t\treturn torch.randn(batch_size, z_dim, 1, 1, device=device)",
            "",
            "\t# The main function, processing a batch of examples",
            "\tdef step(engine, batch):",
            "",
            "\t\t# unpack the batch. It comes from a dataset, so we have <images, labels> pairs. Discard labels.",
            "\t\treal, _ = batch",
            "\t\treal = real.to(device)",
            "",
            "\t\t# -----------------------------------------------------------",
            "\t\t# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))",
            "\t\tnetD.zero_grad()",
            "",
            "\t\t# train with real",
            "\t\toutput = netD(real)",
            "\t\terrD_real = bce(output, real_labels)",
            "\t\tD_x = output.mean().item()",
            "",
            "\t\terrD_real.backward()",
            "",
            "\t\t# get fake image from generator",
            "\t\tnoise = get_noise()",
            "\t\tfake = netG(noise)",
            "",
            "\t\t# train with fake",
            "\t\toutput = netD(fake.detach())",
            "\t\terrD_fake = bce(output, fake_labels)",
            "\t\tD_G_z1 = output.mean().item()",
            "",
            "\t\terrD_fake.backward()",
            "",
            "\t\t# gradient update",
            "\t\terrD = errD_real + errD_fake",
            "\t\toptimizerD.step()",
            "",
            "\t\t# -----------------------------------------------------------",
            "\t\t# (2) Update G network: maximize log(D(G(z)))",
            "\t\tnetG.zero_grad()",
            "",
            "\t\t# Update generator. We want to make a step that will make it more likely that discriminator outputs \"real\"",
            "\t\toutput = netD(fake)",
            "\t\terrG = bce(output, real_labels)",
            "\t\tD_G_z2 = output.mean().item()",
            "",
            "\t\terrG.backward()",
            "",
            "\t\t# gradient update",
            "\t\toptimizerG.step()",
            "",
            "\t\treturn {",
            "\t\t\t'errD': errD.item(),",
            "\t\t\t'errG': errG.item(),",
            "\t\t\t'D_x': D_x,",
            "\t\t\t'D_G_z1': D_G_z1,",
            "\t\t\t'D_G_z2': D_G_z2",
            "\t\t}",
            "",
            "\t# ignite objects",
            "\ttrainer = Engine(step)",
            "\tcheckpoint_handler = ModelCheckpoint(output_dir, CKPT_PREFIX, save_interval=1, n_saved=10, require_empty=False)",
            "\ttimer = Timer(average=True)",
            "",
            "\t# attach running average metrics",
            "\tmonitoring_metrics = ['errD', 'errG', 'D_x', 'D_G_z1', 'D_G_z2']",
            "\tRunningAverage(alpha=alpha, output_transform=lambda x: x['errD']).attach(trainer, 'errD')",
            "\tRunningAverage(alpha=alpha, output_transform=lambda x: x['errG']).attach(trainer, 'errG')",
            "\tRunningAverage(alpha=alpha, output_transform=lambda x: x['D_x']).attach(trainer, 'D_x')",
            "\tRunningAverage(alpha=alpha, output_transform=lambda x: x['D_G_z1']).attach(trainer, 'D_G_z1')",
            "\tRunningAverage(alpha=alpha, output_transform=lambda x: x['D_G_z2']).attach(trainer, 'D_G_z2')",
            "",
            "\t# attach progress bar",
            "\tpbar = ProgressBar()",
            "\tpbar.attach(trainer, metric_names=monitoring_metrics)",
            "",
            "\t@trainer.on(Events.ITERATION_COMPLETED)",
            "\tdef print_logs(engine):",
            "\t\tif (engine.state.iteration - 1) % PRINT_FREQ == 0:",
            "\t\t\tfname = os.path.join(output_dir, LOGS_FNAME)",
            "\t\t\tcolumns = engine.state.metrics.keys()",
            "\t\t\tvalues = [str(round(value, 5)) for value in engine.state.metrics.values()]",
            "",
            "\t\t\twith open(fname, 'a') as f:",
            "\t\t\t\tif f.tell() == 0:",
            "\t\t\t\t\tprint('\\t'.join(columns), file=f)",
            "\t\t\t\tprint('\\t'.join(values), file=f)",
            "",
            "\t\t\tmessage = '[{epoch}/{max_epoch}][{i}/{max_i}]'.format(epoch=engine.state.epoch,",
            "\t\t\t\t\t\t\t\t                                  max_epoch=epochs,",
            "\t\t\t\t\t\t\t\t                                  i=(engine.state.iteration % len(loader)),",
            "\t\t\t\t\t\t\t\t                                  max_i=len(loader))",
            "\t\t\tfor name, value in zip(columns, values):",
            "\t\t\t\tmessage += ' | {name}: {value}'.format(name=name, value=value)",
            "",
            "\t\t\tpbar.log_message(message)",
            "",
            "\t# adding handlers using `trainer.on` decorator API",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef save_fake_example(engine):",
            "\t\tfake = netG(fixed_noise)",
            "\t\tpath = os.path.join(output_dir, FAKE_IMG_FNAME.format(engine.state.epoch))",
            "\t\tvutils.save_image(fake.detach(), path, normalize=True)",
            "",
            "\t# adding handlers using `trainer.on` decorator API",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef save_real_example(engine):",
            "\t\timg, y = engine.state.batch",
            "\t\tpath = os.path.join(output_dir, REAL_IMG_FNAME.format(engine.state.epoch))",
            "\t\tvutils.save_image(img, path, normalize=True)",
            "",
            "\t# adding handlers using `trainer.add_event_handler` method API",
            "\ttrainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=checkpoint_handler,",
            "\t\t\t\t\t\t\t  to_save={",
            "\t\t\t\t\t\t\t\t  'netG': netG,",
            "\t\t\t\t\t\t\t\t  'netD': netD",
            "\t\t\t\t\t\t\t  })",
            "",
            "\t# automatically adding handlers via a special `attach` method of `Timer` handler",
            "\ttimer.attach(trainer, start=Events.EPOCH_STARTED, resume=Events.ITERATION_STARTED,",
            "\t\t\t\t pause=Events.ITERATION_COMPLETED, step=Events.ITERATION_COMPLETED)",
            "",
            "\t# adding handlers using `trainer.on` decorator API",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef print_times(engine):",
            "\t\tpbar.log_message('Epoch {} done. Time per batch: {:.3f}[s]'.format(engine.state.epoch, timer.value()))",
            "\t\ttimer.reset()",
            "",
            "\t# adding handlers using `trainer.on` decorator API",
            "\t@trainer.on(Events.EPOCH_COMPLETED)",
            "\tdef create_plots(engine):",
            "\t\ttry:",
            "\t\t\timport matplotlib as mpl",
            "\t\t\tmpl.use('agg')",
            "",
            "\t\t\timport numpy as np",
            "\t\t\timport pandas as pd",
            "\t\t\timport matplotlib.pyplot as plt",
            "",
            "\t\texcept ImportError:",
            "\t\t\twarnings.warn('Loss plots will not be generated -- pandas or matplotlib not found')",
            "",
            "\t\telse:",
            "\t\t\tdf = pd.read_csv(os.path.join(output_dir, LOGS_FNAME), delimiter='\\t')",
            "\t\t\tx = np.arange(1, engine.state.iteration + 1, PRINT_FREQ)",
            "\t\t\t_ = df.plot(x=x, subplots=True, figsize=(20, 20))",
            "\t\t\t_ = plt.xlabel('Iteration number')",
            "\t\t\tfig = plt.gcf()",
            "\t\t\tpath = os.path.join(output_dir, PLOT_FNAME)",
            "",
            "\t\t\tfig.savefig(path)",
            "",
            "\t# adding handlers using `trainer.on` decorator API",
            "\t@trainer.on(Events.EXCEPTION_RAISED)",
            "\tdef handle_exception(engine, e):",
            "\t\tif isinstance(e, KeyboardInterrupt) and (engine.state.iteration > 1):",
            "\t\t\tengine.terminate()",
            "\t\t\twarnings.warn('KeyboardInterrupt caught. Exiting gracefully.')",
            "",
            "\t\t\tcreate_plots(engine)",
            "\t\t\tcheckpoint_handler(engine, {",
            "\t\t\t\t'netG_exception': netG,",
            "\t\t\t\t'netD_exception': netD",
            "\t\t\t})",
            "",
            "\t\telse:",
            "\t\t\traise e",
            "",
            "\t# Setup is done. Now let's run the training",
            "\ttrainer.run(loader, epochs)",
            "",
            "",
            "if __name__ == '__main__':",
            "\tparser = argparse.ArgumentParser()",
            "",
            "\tparser.add_argument('--dataset',",
            "\t\t\t\t\t\trequired=True, choices={'cifar10', 'lsun', 'imagenet', 'folder', 'lfw', 'fake', 'mnist'},",
            "\t\t\t\t\t\thelp='Type of the dataset to be used.')",
            "",
            "\tparser.add_argument('--dataroot',",
            "\t\t\t\t\t\trequired=True,",
            "\t\t\t\t\t\thelp='path to dataset')",
            "",
            "\tparser.add_argument('--workers',",
            "\t\t\t\t\t\ttype=int, default=2,",
            "\t\t\t\t\t\thelp='number of data loading workers')",
            "",
            "\tparser.add_argument('--batch-size',",
            "\t\t\t\t\t\ttype=int, default=64,",
            "\t\t\t\t\t\thelp='input batch size')",
            "",
            "\tparser.add_argument('--z-dim',",
            "\t\t\t\t\t\ttype=int, default=100,",
            "\t\t\t\t\t\thelp='size of the latent z vector')",
            "",
            "\tparser.add_argument('--g-filters',",
            "\t\t\t\t\t\ttype=int, default=64,",
            "\t\t\t\t\t\thelp='Number of filters in the second-to-last generator deconv layer')",
            "",
            "\tparser.add_argument('--d-filters',",
            "\t\t\t\t\t\ttype=int, default=64,",
            "\t\t\t\t\t\thelp='Number of filters in first discriminator conv layer')",
            "",
            "\tparser.add_argument('--epochs',",
            "\t\t\t\t\t\ttype=int, default=25,",
            "\t\t\t\t\t\thelp='number of epochs to train for')",
            "",
            "\tparser.add_argument('--lr',",
            "\t\t\t\t\t\ttype=float, default=0.0002,",
            "\t\t\t\t\t\thelp='learning rate')",
            "",
            "\tparser.add_argument('--beta-1',",
            "\t\t\t\t\t\ttype=float, default=0.5,",
            "\t\t\t\t\t\thelp='beta_1 for adam')",
            "",
            "\tparser.add_argument('--no-cuda',",
            "\t\t\t\t\t\taction='store_true',",
            "\t\t\t\t\t\thelp='disables cuda')",
            "",
            "\tparser.add_argument('--saved-G',",
            "\t\t\t\t\t\tdefault='',",
            "\t\t\t\t\t\thelp=\"path to pickled generator (to continue training)\")",
            "",
            "\tparser.add_argument('--saved-D',",
            "\t\t\t\t\t\tdefault='',",
            "\t\t\t\t\t\thelp=\"path to pickled discriminator (to continue training)\")",
            "",
            "\tparser.add_argument('--output-dir',",
            "\t\t\t\t\t\tdefault='.',",
            "\t\t\t\t\t\thelp='directory to output images and model checkpoints')",
            "",
            "\tparser.add_argument('--seed',",
            "\t\t\t\t\t\ttype=int,",
            "\t\t\t\t\t\thelp='manual seed')",
            "",
            "\tparser.add_argument('--alpha',",
            "\t\t\t\t\t\ttype=float, default=0.98,",
            "\t\t\t\t\t\thelp='smoothing constant for exponential moving averages')",
            "",
            "\targs = parser.parse_args()",
            "\tdev = 'cpu' if (not torch.cuda.is_available() or args.no_cuda) else 'cuda:0'",
            "",
            "\ttry:",
            "\t\tos.makedirs(args.output_dir)",
            "\texcept FileExistsError:",
            "\t\tif (not os.path.isdir(args.output_dir)) or (len(os.listdir(args.output_dir)) > 0):",
            "\t\t\traise FileExistsError(\"Please provide a path to a non-existing or empty directory.\")",
            "",
            "\tmain(dataset=args.dataset, dataroot=args.dataroot,",
            "\t\t z_dim=args.z_dim, g_filters=args.g_filters, d_filters=args.d_filters,",
            "\t\t batch_size=args.batch_size, epochs=args.epochs,",
            "\t\t learning_rate=args.lr, beta_1=args.beta_1,",
            "\t\t saved_D=args.saved_D, saved_G=args.saved_G,",
            "\t\t seed=args.seed,",
            "\t\t device=dev, n_workers=args.workers,",
            "\t\t alpha=args.alpha, output_dir=args.output_dir)"
        ]
    },
    "RL REINFORCE Example": {
        "prefix": "ignite:examples:vpg",
        "description": "VPG code example",
        "body": [
            "import argparse",
            "",
            "import numpy as np",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "try:",
            "\timport gym",
            "except ImportError:",
            "\traise RuntimeError(\"Please install opengym: pip install gym\")",
            "",
            "",
            "from ignite.engine import Engine, Events",
            "",
            "",
            "class Policy(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "\t\tself.affine2 = nn.Linear(128, 2)",
            "",
            "\t\tself.saved_log_probs = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(self.affine1(x))",
            "\t\taction_scores = self.affine2(x)",
            "\t\treturn F.softmax(action_scores, dim=1)",
            "",
            "",
            "def select_action(model, observation):",
            "\tstate = torch.from_numpy(observation).float().unsqueeze(0)",
            "\tprobs = model(state)",
            "\tm = Categorical(probs)",
            "\taction = m.sample()",
            "\tmodel.saved_log_probs.append(m.log_prob(action))",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode(model, optimizer, gamma, eps):",
            "\tR = 0",
            "\tpolicy_loss = []",
            "\trewards = []",
            "\tfor r in model.rewards[::-1]:",
            "\t\tR = r + gamma * R",
            "\t\trewards.insert(0, R)",
            "\trewards = torch.tensor(rewards)",
            "\trewards = (rewards - rewards.mean()) / (rewards.std() + eps)",
            "\tfor log_prob, reward in zip(model.saved_log_probs, rewards):",
            "\t\tpolicy_loss.append(-log_prob * reward)",
            "\toptimizer.zero_grad()",
            "\tpolicy_loss = torch.cat(policy_loss).sum()",
            "\tpolicy_loss.backward()",
            "\toptimizer.step()",
            "\tdel model.rewards[:]",
            "\tdel model.saved_log_probs[:]",
            "",
            "",
            "EPISODE_STARTED = Events.EPOCH_STARTED",
            "EPISODE_COMPLETED = Events.EPOCH_COMPLETED",
            "",
            "",
            "def main(env, args):",
            "",
            "\tmodel = Policy()",
            "\toptimizer = optim.Adam(model.parameters(), lr=1e-2)",
            "\teps = np.finfo(np.float32).eps.item()",
            "\ttimesteps = list(range(10000))",
            "",
            "\tdef run_single_timestep(engine, timestep):",
            "\t\tobservation = engine.state.observation",
            "\t\taction = select_action(model, observation)",
            "\t\tengine.state.observation, reward, done, _ = env.step(action)",
            "\t\tif args.render:",
            "\t\t\tenv.render()",
            "\t\tmodel.rewards.append(reward)",
            "",
            "\t\tif done:",
            "\t\t\tengine.terminate_epoch()",
            "\t\t\tengine.state.timestep = timestep",
            "",
            "\ttrainer = Engine(run_single_timestep)",
            "",
            "\t@trainer.on(Events.STARTED)",
            "\tdef initialize(engine):",
            "\t\tengine.state.running_reward = 10",
            "",
            "\t@trainer.on(EPISODE_STARTED)",
            "\tdef reset_environment_state(engine):",
            "\t\tengine.state.observation = env.reset()",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef update_model(engine):",
            "\t\tt = engine.state.timestep",
            "\t\tengine.state.running_reward = engine.state.running_reward * 0.99 + t * 0.01",
            "\t\tfinish_episode(model, optimizer, args.gamma, eps)",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef log_episode(engine):",
            "\t\ti_episode = engine.state.epoch",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(",
            "\t\t\t\ti_episode, engine.state.timestep, engine.state.running_reward))",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef should_finish_training(engine):",
            "\t\trunning_reward = engine.state.running_reward",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, engine.state.timestep))",
            "\t\t\tengine.should_terminate = True",
            "",
            "\ttrainer.run(timesteps, max_epochs=args.max_episodes)",
            "",
            "",
            "if __name__ == '__main__':",
            "",
            "\tparser = argparse.ArgumentParser(description='PyTorch REINFORCE example')",
            "\tparser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "\tparser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\t\thelp='random seed (default: 543)')",
            "\tparser.add_argument('--render', action='store_true',",
            "\t\t\t\t\t\thelp='render the environment')",
            "\tparser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "\tparser.add_argument('--max-episodes', type=int, default=1000000, metavar='N',",
            "\t\t\t\t\t\thelp='Number of episodes for the training (default: 1000000)')",
            "\targs = parser.parse_args()",
            "",
            "\tenv = gym.make('CartPole-v0')",
            "\tenv.seed(args.seed)",
            "\ttorch.manual_seed(args.seed)",
            "",
            "\tmain(env, args)"
        ]
    },
    "RL Actor-Critic Example": {
        "prefix": "ignite:examples:ac",
        "description": "Actor-Critic code example",
        "body": [
            "import argparse",
            "from collections import namedtuple",
            "",
            "import numpy as np",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "try:",
            "\timport gym",
            "except ImportError:",
            "\traise RuntimeError(\"Please install opengym: pip install gym\")",
            "",
            "",
            "from ignite.engine import Engine, Events",
            "",
            "",
            "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])",
            "",
            "",
            "class Policy(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "\t\tself.action_head = nn.Linear(128, 2)",
            "\t\tself.value_head = nn.Linear(128, 1)",
            "",
            "\t\tself.saved_actions = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(self.affine1(x))",
            "\t\taction_scores = self.action_head(x)",
            "\t\tstate_values = self.value_head(x)",
            "\t\treturn F.softmax(action_scores, dim=-1), state_values",
            "",
            "",
            "def select_action(model, observation):",
            "\tobservation = torch.from_numpy(observation).float()",
            "\tprobs, observation_value = model(observation)",
            "\tm = Categorical(probs)",
            "\taction = m.sample()",
            "\tmodel.saved_actions.append(SavedAction(m.log_prob(action), observation_value))",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode(model, optimizer, gamma, eps):",
            "\tR = 0",
            "\tsaved_actions = model.saved_actions",
            "\tpolicy_losses = []",
            "\tvalue_losses = []",
            "\trewards = []",
            "\tfor r in model.rewards[::-1]:",
            "\t\tR = r + gamma * R",
            "\t\trewards.insert(0, R)",
            "\trewards = torch.tensor(rewards)",
            "\trewards = (rewards - rewards.mean()) / (rewards.std() + eps)",
            "\tfor (log_prob, value), r in zip(saved_actions, rewards):",
            "\t\treward = r - value.item()",
            "\t\tpolicy_losses.append(-log_prob * reward)",
            "\t\tvalue_losses.append(F.smooth_l1_loss(value, torch.tensor([r])))",
            "\toptimizer.zero_grad()",
            "\tloss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()",
            "\tloss.backward()",
            "\toptimizer.step()",
            "\tdel model.rewards[:]",
            "\tdel model.saved_actions[:]",
            "",
            "",
            "EPISODE_STARTED = Events.EPOCH_STARTED",
            "EPISODE_COMPLETED = Events.EPOCH_COMPLETED",
            "",
            "",
            "def main(env, args):",
            "",
            "\tmodel = Policy()",
            "\toptimizer = optim.Adam(model.parameters(), lr=3e-2)",
            "\teps = np.finfo(np.float32).eps.item()",
            "\ttimesteps = list(range(10000))",
            "",
            "\tdef run_single_timestep(engine, timestep):",
            "\t\tobservation = engine.state.observation",
            "\t\taction = select_action(model, observation)",
            "\t\tengine.state.observation, reward, done, _ = env.step(action)",
            "\t\tif args.render:",
            "\t\t\tenv.render()",
            "\t\tmodel.rewards.append(reward)",
            "",
            "\t\tif done:",
            "\t\t\tengine.terminate_epoch()",
            "\t\t\tengine.state.timestep = timestep",
            "",
            "\ttrainer = Engine(run_single_timestep)",
            "",
            "\t@trainer.on(Events.STARTED)",
            "\tdef initialize(engine):",
            "\t\tengine.state.running_reward = 10",
            "",
            "\t@trainer.on(EPISODE_STARTED)",
            "\tdef reset_environment_state(engine):",
            "\t\tengine.state.observation = env.reset()",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef update_model(engine):",
            "\t\tt = engine.state.timestep",
            "\t\tengine.state.running_reward = engine.state.running_reward * 0.99 + t * 0.01",
            "\t\tfinish_episode(model, optimizer, args.gamma, eps)",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef log_episode(engine):",
            "\t\ti_episode = engine.state.epoch",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(",
            "\t\t\t\ti_episode, engine.state.timestep, engine.state.running_reward))",
            "",
            "\t@trainer.on(EPISODE_COMPLETED)",
            "\tdef should_finish_training(engine):",
            "\t\trunning_reward = engine.state.running_reward",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, engine.state.timestep))",
            "\t\t\tengine.should_terminate = True",
            "",
            "\ttrainer.run(timesteps, max_epochs=args.max_episodes)",
            "",
            "",
            "if __name__ == '__main__':",
            "",
            "\tparser = argparse.ArgumentParser(description='Ignite actor-critic example')",
            "\tparser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "\tparser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\t\thelp='random seed (default: 1)')",
            "\tparser.add_argument('--render', action='store_true',",
            "\t\t\t\t\t\thelp='render the environment')",
            "\tparser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "\tparser.add_argument('--max-episodes', type=int, default=1000000, metavar='N',",
            "\t\t\t\t\t\thelp='Number of episodes for the training (default: 1000000)')",
            "\targs = parser.parse_args()",
            "",
            "\tenv = gym.make('CartPole-v0')",
            "\tenv.seed(args.seed)",
            "\ttorch.manual_seed(args.seed)",
            "",
            "\tmain(env, args)"
        ]
    }
}