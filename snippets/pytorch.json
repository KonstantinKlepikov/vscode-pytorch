{   
    "PyTorch Imports": {
        "prefix": "pytorch:imports",
        "description": "Common pytorch imports",
        "body":[
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F"
        ]
    },
    "Check Device": {
        "prefix": "pytorch:device",
        "description": "Check the available device",
        "body":[
            "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
        ]
    },
    "Optimizer": {
        "prefix": "pytorch:optimizer",
        "description": "Select an optimizer",
        "body":[
            "optimizer = torch.optim.${1|Adadelta,Adagrad,Adam,SparseAdam,Adamax,ASGD,LBFGS,RMSprop,Rprop,SGD|}${2:net}.parameters(), lr=${3:1e-2})"
        ]
    },
    "Classification Loss": {
        "prefix": "pytorch:loss_class",
        "description": "Loads a loss function for classification provided by pytorch",
        "body":[
            "criterion = nn.${1|CrossEntropyLoss,NLLLoss,PoissonNLLLoss,BCELoss,BCEWithLogitsLoss,MarginRankingLoss,HingeEmbeddingLoss,MultiLabelMarginLoss,SoftMarginLoss,MultiLabelSoftMarginLoss,CosineEmbeddingLoss,MultiMarginLoss,TripletMarginLoss|}()"
        ]
    },
    "Regression Loss": {
        "prefix": "pytorch:loss_reg",
        "description": "Loads a loss function for regression provided by pytorch",
        "body":[
            "criterion = nn.${1|L1Loss,MSELoss,KLDivLoss,SmoothL1Loss|}()"
        ]
    },
    "PyTorch Module": {
        "prefix": "pytorch:module",
        "description": "Creates a custom class template which inherits from torch.nn.Module",
        "body": [
            "class ${1:MyModule}(nn.Module):",            
            "\t\"\"\"Some Information about ${1:MyModule}\"\"\"",
            "\tdef __init__(self):",
            "\t\tsuper(${1:MyModule}, self).__init__()",
            "",
            "\tdef forward(self, x):",
            "",
            "\t\treturn x"
        ]
    },
    "Sequential": {
        "prefix": "pytorch:sequential",
        "description": "Builds a sequential model",
        "body": [
            "net = nn.Sequential(${1| ,*[]|}).to(${2:device})"
        ]
    },
    "PyTorch Autograd Function": {
        "prefix": "pytorch:function",
        "description": "Creates a custom autograd function template which inherits from torch.autograd.Function",
        "body": [
            "class ${1:MyFunction}(torch.autograd.Function):",            
            "\t\"\"\"Some Information about ${1:MyFunction}\"\"\"",
            "",
            "\t@staticmethod",
            "\tdef forward(ctx, input):",
            "",
            "\t\treturn",
            "",
            "\t@staticmethod",
            "\tdef backward(ctx, grad_output)",
            "",
            "\t\treturn"
        ]
    },
    "Initialize": {
        "prefix": "pytorch:init",
        "description": "Creates an initializer function and applies it to the given neural network",
        "body": [
            "def init_weights(m):",
            "\tclassname = m.__class__.__name__",
            "\tif classname.find('Linear') != -1 or classname.find('Bilinear') != -1:",
            "\t\tnn.init.${1|kaiming_uniform_(a=2\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tif m.bias: nn.init.${2|zeros(,uniform_(a=0\\, b=1\\, ,normal_(mean=0\\, std=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('Conv') != -1:",
            "\t\tnn.init.${3|kaiming_uniform_(a=2\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,dirac_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tif m.bias: nn.init.${4|zeros(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('BatchNorm') != -1 or classname.find('GroupNorm') != -1 or classname.find('LayerNorm') != -1:",
            "\t\tnn.init.${5|uniform_(a=0\\, b=1\\, ,normal_(mean=0\\, std=1\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tnn.init.${6|zeros(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('Cell') != -1:",
            "\t\tnn.init.${7|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight_hh)",
            "\t\tnn.init.${8|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight_ih)",
            "\t\tnn.init.${9|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=m.bias_hh)",
            "\t\tnn.init.${10|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=m.bias_ih)",
            "",
            "\telif classname.find('RNN') != -1 or classname.find('LSTM') != -1 or classname.find('GRU') != -1:",
            "\t\tfor w in m.all_weights:",
            "\t\t\tnn.init.${11|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=w[2].data)",
            "\t\t\tnn.init.${12|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=w[3].data)",
            "\t\t\tnn.init.${13|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=w[0].data)",
            "\t\t\tnn.init.${14|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=w[1].data)",
            "",
            "\tif classname.find('Embedding') != -1:",
            "\t\tnn.init.${1|normal_(mean=0\\, std=1\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "",
            "${15:net}.apply(init_weights)"
        ]
    },
    "Train Loop": {
        "prefix": "pytorch:train",
        "description": "Creates a simple training loop",
        "body":[
            "# loop over the dataset multiple times",
            "for epoch in range(${1:5}):",
            "\trunning_loss = 0.0",
            "\tfor i, data in enumerate(${2:trainloader}, 0):",
            "\t\tinputs, labels = data",
            "\t\tinputs, labels = inputs.to(${3:device}), labels.to(${3:device})",
            "",
            "\t\t# zero the parameter gradients",
            "\t\t${4:optimizer}.zero_grad()",
            "",
            "\t\t# forward + backward + optimize",
            "\t\toutputs = ${5:net}(inputs)",
            "\t\tloss = ${6:criterion}(outputs, labels)",
            "\t\tloss.backward()",
            "\t\t${4:optimizer}.step()",
            "",
            "\t\trunning_loss += loss.item()",
            "",
            "\tprint('Loss: {}'.format(running_loss)",
            "",
            "print('Finished Training')"
        ]
    },
    "Freeze Layers": {
        "prefix": "pytorch:freeze",
        "desription": "Freeze all layers of the network",
        "body": [
            "for params in ${1:net}.parameters():",
            "\tparams.require_grad = False"
        ]
    },
    "Unfreeze Layers":{
        "prefix": "pytorch:unfreeze",
        "desription": "Unfreeze all layers of the network",
        "body": [
            "for params in ${1:net}.parameters():",
            "\tparams.require_grad = True"
        ]
    },
    "Activation":{
        "prefix": "pytorch:layer:activation",
        "description": "Adds a non-linear activation",
        "body": [
            "${1:nonlin} = nn.${2|ELU(alpha=1.\\, inplace=False),Hardshrink(lambd=0.5),Hardtanh(min_val=-1\\, max_val=1\\, inplace=False\\, min_value=None\\, max_value=None),LeakyReLU(negative_slope=0.01\\, inplace=False),LogSigmoid,PReLU(num_parameters=1\\, init=0.25),ReLU(inplace=False),ReLU6(inplace=False),RReLU(lower=0.125\\, upper=0.3333333333333333\\, inplace=False),SELU(inplace=False),Sigmoid,Softplus(beta=1\\, threshold=20),Softshrink(lambd=0.5),Softsign,Tanh,Tanhshrink,Threshold(threshold\\, value\\, inplace=False),Softmin(dim=None),Softmax(dim=None),Softmax2d,LogSoftmax(dim=None),AdaptiveLogSoftmaxWithLogits(in_features\\, n_classes\\, cutoffs\\, div_value=4.0\\, head_bias=True)|}"
        ]
    },
    "Convolution Layer":{
        "prefix": "pytorch:layer:conv",
        "description": "Creates a convolutional layer",
        "body": [
            "${1:conv} = nn.${2|Conv1d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,Conv2d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,Conv3d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,ConvTranspose1d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,ConvTranspose2d/in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,ConvTranspose3d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,Unfold(dilation=1\\, ,Fold(outputsize\\, |}kernel_size=2, padding=0, stride=1)"
        ]
    },
    "Pooling Layer":{
        "prefix": "pytorch:layer:pooling",
        "description": "Creates a pooling layer",
        "body": [
            "${1:pool} = nn.${2|MaxPool1d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxPool2d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxPool3d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxUnpool1d(kernel_size\\, stride=None\\, padding=0),MaxUnpool2d(kernel_size\\, stride=None\\, padding=0),MaxUnpool3d(kernel_size\\, stride=None\\, padding=0),AvgPool1d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),AvgPool2d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),AvgPool3d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),FractionalMaxPool2d(kernel_size\\, output_size=None\\, output_ratio=None\\, return_indices=False\\, random_samples=None),LPPool1d(norm_type\\, kernel_size\\, stride=None\\, ceil_mode=False),LPPool2d(norm_type\\, kernel_size\\, stride=None\\, ceil_mode=False),AdaptiveMaxPool1d(output_size\\, return_indices=False),AdaptiveMaxPool2d(output_size\\, return_indices=False),AdaptiveMaxPool3d(output_size\\, return_indices=False),AdaptiveAvgPool1d(output_size),AdaptiveAvgPool2d(output_size),AdaptiveAvgPool3d(output_size)|}"
        ]
    },
    "Padding Layer":{
        "prefix": "pytorch:layer:padding",
        "description": "Creates a padding layer",
        "body": [
            "${1:padding} = nn.${2|ReflectionPad1d(,ReflectionPad2d(,ReplicationPad1d(,ReplicationPad2d(,ReplicationPad3d(,ZeroPad2d(,ConstantPad1d(value=3.5\\, ,ConstantPad2d(value=3.5\\, ,ConstantPad3d(value=3.5\\, |}padding=${3:(2,2)}"
        ]
    },
    "Recurrent Layer":{
        "prefix": "pytorch:layer:recurrent",
        "description": "Creates a recurrent layer",
        "body": [
            "${1:recurrent} = nn.${2|RNN,LSTM,GRU,RNNCell,LSTMCell,GRUCell|}(${3:input_size}, ${4:hidden_size}, bias=${5:True})"
        ]
    },
    "Normalization Layer":{
        "prefix": "pytorch:layer:norm",
        "description": "Creates a normalization layer",
        "body": [
            "${1:norm} = nn.${2|BatchNorm1d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),BatchNorm2d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),BatchNorm3d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),GroupNorm(num_groups\\, num_channels\\, eps=1e-5\\, affine=True),InstanceNorm1d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),InstanceNorm2d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),InstanceNorm3d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),LayerNorm(normalized_shape\\, eps=1e-5\\, elementwise_affine=True),LocalResponseNorm(size\\, alpha=1e-4\\, beta=0.75\\, k=1)|}"
        ]
    },
    "Linear Layer":{
        "prefix": "pytorch:layer:linear",
        "description": "Creates a linear layer",
        "body": [
            "${1:linear} = nn.${2|Linear(in_feature\\, ,Bilinear(in_features1\\, in_features2\\, |}out_features, bias=True)"
        ]
    },
    "Dropout":{
        "prefix": "pytorch:layer:dropout",
        "description": "Adds dropout",
        "body": [
            "${1:drop} = nn.${2|Dropout,Dropout2d,Dropout3d,AlphaDropout|}(p=${3:0.5}, inplace=${4|False,True|})"
        ]
    },
    "Sparse Layer":{
        "prefix": "pytorch:layer:sparse",
        "description": "Creates a sparse layer",
        "body": [
            "${1:sparse} = nn.${2|Embedding,EmbeddingBag|}(${3:num_embeddings}, ${4:embedding_dim})"
        ]
    },
    "Vision Layer":{
        "prefix": "pytorch:layer:vision",
        "description": "Creates a vision layer",
        "body": [
            "${1:vision} = nn.${2|PixelShuffle(upscale_factor),Upsample(size=None\\, scale_factor=None\\, mode='nearest'\\, align_corners=None),UpsamplingNearest2d(size=None\\, scale_factor=None),UpsamplingBilinear2d(size=None\\, scale_factor=None)|}"
        ]
    },
    "Distance Layer": {
        "prefix": "pytorch:layer:distance",
        "description": "Creates a distance layer",
        "body": [
            "${1:distance} = nn.${2|CosineSimilarity,PairwiseDistance|}()"
        ]
    },
    "Activation Function":{
        "prefix": "pytorch:F:activation",
        "description": "Applies a nonlinearity function",
        "body": [
            "F.${1|threshold(input\\, threshold\\, value\\, inplace=False),relu(input\\, inplace=False),relu6(input\\, inplace=False),hardtanh(input\\, min_val=-1.\\, max_val=1.\\, inplace=False),elu(input\\, alpha=1.0\\, inplace=False),selu(input\\, inplace=False),leaky_relu(input\\, negative_slope=0.01\\, inplace=False),prelu(input\\, weight),rrelu(input\\, lower=1./8\\, upper=1./3\\, training=False\\, inplace=False),glu(input\\, dim=-1),logsigmoid(input),hardshrink(input\\, lambd=0.5),tanhshrink(input),softsign(input),softplus(input\\, beta=1\\, threshold=20),softmin(input\\, dim=None\\, _stacklevel=3),softmax(input\\, dim=None\\, _stacklevel=3),softshrink(input\\, lambd=0.5),gumbel_softmax(logits\\, tau=1\\, hard=False\\, eps=1e-10),log_softmax(input\\, dim=None\\, _stacklevel=3),tanh(input),sigmoid(input)|}"
        ]
    },
    "Convolution Function":{
        "prefix": "pytorch:F:conv",
        "description": "Applies a convolution function",
        "body": [
            "F.${1|conv1d,conv2d,conv3d,conv_transpose1d,conv_transpose2d,conv_transpose3d|}(${2:input}, ${3:weight}, bias=None, stride=1, padding=0)"
        ]
    },
    "Pooling Function":{
        "prefix": "pytorch:F:pooling",
        "description": "Applies a pooling function",
        "body": [
            "F.${1|avg_pool1d(input\\, kernel_size\\, stride=None\\, padding=0),avg_pool2d(input\\, kernel_size\\, stride=None\\, padding=0),avg_pool3d(input\\, kernel_size\\, stride=None\\, padding=0),max_pool1d(input\\, kernel_size\\, stride=None\\, padding=0),max_pool2d(input\\, kernel_size\\, stride=None\\, padding=0,max_pool3d(input\\, kernel_size\\, stride=None\\, padding=0),max_unpool1d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),max_unpool2d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),max_unpool3d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),lp_pool1d(input\\, norm_type\\, kernel_size\\, stride=None),lp_pool2d(input\\, norm_type\\, kernel_size\\, stride=None),adaptive_max_pool1d(input\\, output_size),adaptive_max_pool2d(input\\, output_size),adaptive_max_pool3d(input\\, output_size),adaptive_avg_pool1d(input\\, output_size),adaptive_avg_pool2d(input\\, output_size),adaptive_avg_pool3d(input\\, output_size)|}"
        ]
    },
    "Normalization Function":{
        "prefix": "pytorch:F:norm",
        "description": "Applies a normalization function",
        "body": [
            "F.${1|batch_norm(input\\, running_mean\\, running_var),instance_norm(input\\, running_mean=None\\, running_var=None),layer_norm(input\\, normalized_shape),local_response_norm(input\\, size),normalize(input)|}"
        ]
    },
    "Linear Function":{
        "prefix": "pytorch:F:linear",
        "description": "Applies a linear function",
        "body": [
            "F.${1|linear(input\\, weight),bilinear(input1\\, input2\\, weight)|}"
        ]
    },
    "Dropout Function":{
        "prefix": "pytorch:F:dropout",
        "description": "Applies a dropout function",
        "body": [
            "F.${1|dropout,dropout2d,dropout3d,alpha_dropout|}(${2:input}, p=${3:0.5})"
        ]
    },
    "Sparse Function":{
        "prefix": "pytorch:F:sparse",
        "description": "Applies an embedding function",
        "body": [
            "F.${1|embedding,embedding_bag|}(${2:input}, ${3:weight})"
        ]
    },
    "Distance Function":{
        "prefix": "pytorch:F:distance",
        "description": "Applies a distance function",
        "body": [
            "F.${1|pairwise_distance,cosine_similarity|}(${2:x1}, ${3:x2})"
        ]
    },
    "Vision Function": {
        "prefix": "pytorch:F:vision",
        "description": "Applies a vision function",
        "body": [
            "F.${1|pixel_shuffle(input\\, upscale_factor),pad(input\\, pad),interpolate(input\\, size=None\\, scale_factor=None),upsample(input\\, size=None\\, scale_factor=None),upsample_nearest(input\\, size=None\\, scale_factor=None),upsample_bilinear(input\\, size=None\\, scale_factor=None),grid_sample(input\\, grid),affine_grid(theta\\, size)|}"
        ]
    },
    "Loss Function": {
        "prefix": "pytorch:F:loss",
        "description": "Applies a loss function",
        "body": [
            "F.${1|cross_entropy,binary_cross_entropy,binary_cross_entropy_with_logits,poisson_nll_loss,hinge_embedding_loss,kl_div,l1_loss,smooth_l1_loss,mse_loss,multilabel_margin_loss,multilabel_soft_margin_loss,multi_margin_loss,nll_loss,soft_margin_loss|}(${2:input}, ${3:target})"
        ]
    },
    "Resnet Basic Block":{
        "prefix": "pytorch:layer:resnet:block",
        "description": "Creates a Resnet basic block",
        "body": [
            "class BasicBlock(nn.Module):",
            "\t# see https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html",
            "\tdef __init__(self, inplanes, planes, stride=1):",
            "\t\tsuper(BasicBlock, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)",
            "\t\tself.bn1 = nn.BatchNorm2d(planes)",
            "\t\tself.relu = nn.ReLU(inplace=True)",
            "\t\tself.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)",
            "\t\tself.bn2 = nn.BatchNorm2d(planes)",
            "",
            "\tdef forward(self, x):",
            "\t\tresidual = x",
            "\t\tout = self.conv1(x)",
            "\t\tout = self.bn1(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv2(out)",
            "\t\tout = self.bn2(out)",
            "\t\tout += residual",
            "\t\tout = self.relu(out)",
            "\t\treturn out"
        ]
    },
    "Resnet Bottleneck Block":{
        "prefix": "pytorch:layer:resnet:bottleneck",
        "description": "Creates a Resnet bottleneck block",
        "body": [
            "class Bottleneck(nn.Module):",
            "\t# see https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html ",
            "\tdef __init__(self, inplanes, planes, stride=1, downsample=None):",
            "\t\tsuper(Bottleneck, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)",
            "\t\tself.bn1 = nn.BatchNorm2d(planes)",
            "\t\tself.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)",
            "\t\tself.bn2 = nn.BatchNorm2d(planes)",
            "\t\tself.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)",
            "\t\tself.bn3 = nn.BatchNorm2d(planes * 4)",
            "\t\tself.relu = nn.ReLU(inplace=True)",
            "",
            "\tdef forward(self, x):",
            "\t\tresidual = x",
            "\t\tout = self.conv1(x)",
            "\t\tout = self.bn1(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv2(out)",
            "\t\tout = self.bn2(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv3(out)",
            "\t\tout = self.bn3(out)",
            "\t\tout += residual",
            "\t\tout = self.relu(out)",
            "\t\treturn out"
        ]
    },
    "Imagenet Example": {
        "prefix": "pytorch:examples:imagenet",
        "description": "Imagenet code example",
        "body": [
            "import argparse",
            "import os",
            "import random",
            "import shutil",
            "import time",
            "import warnings",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.parallel",
            "import torch.backends.cudnn as cudnn",
            "import torch.distributed as dist",
            "import torch.optim",
            "import torch.utils.data",
            "import torch.utils.data.distributed",
            "import torchvision.transforms as transforms",
            "import torchvision.datasets as datasets",
            "import torchvision.models as models",
            "",
            "model_names = sorted(name for name in models.__dict__",
            "\tif name.islower() and not name.startswith(\"__\")",
            "\tand callable(models.__dict__[name]))",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')",
            "parser.add_argument('data', metavar='DIR',",
            "\t\t\t\t\thelp='path to dataset')",
            "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',",
            "\t\t\t\t\tchoices=model_names,",
            "\t\t\t\t\thelp='model architecture: ' +",
            "\t\t\t\t\t\t' | '.join(model_names) +",
            "\t\t\t\t\t\t' (default: resnet18)')",
            "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',",
            "\t\t\t\t\thelp='number of data loading workers (default: 4)')",
            "parser.add_argument('--epochs', default=90, type=int, metavar='N',",
            "\t\t\t\t\thelp='number of total epochs to run')",
            "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',",
            "\t\t\t\t\thelp='manual epoch number (useful on restarts)')",
            "parser.add_argument('-b', '--batch-size', default=256, type=int,",
            "\t\t\t\t\tmetavar='N', help='mini-batch size (default: 256)')",
            "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,",
            "\t\t\t\t\tmetavar='LR', help='initial learning rate')",
            "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',",
            "\t\t\t\t\thelp='momentum')",
            "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,",
            "\t\t\t\t\tmetavar='W', help='weight decay (default: 1e-4)')",
            "parser.add_argument('--print-freq', '-p', default=10, type=int,",
            "\t\t\t\t\tmetavar='N', help='print frequency (default: 10)')",
            "parser.add_argument('--resume', default='', type=str, metavar='PATH',",
            "\t\t\t\t\thelp='path to latest checkpoint (default: none)')",
            "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',",
            "\t\t\t\t\thelp='evaluate model on validation set')",
            "parser.add_argument('--pretrained', dest='pretrained', action='store_true',",
            "\t\t\t\t\thelp='use pre-trained model')",
            "parser.add_argument('--world-size', default=1, type=int,",
            "\t\t\t\t\thelp='number of distributed processes')",
            "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,",
            "\t\t\t\t\thelp='url used to set up distributed training')",
            "parser.add_argument('--dist-backend', default='gloo', type=str,",
            "\t\t\t\t\thelp='distributed backend')",
            "parser.add_argument('--seed', default=None, type=int,",
            "\t\t\t\t\thelp='seed for initializing training. ')",
            "parser.add_argument('--gpu', default=None, type=int,",
            "\t\t\t\t\thelp='GPU id to use.')",
            "",
            "best_acc1 = 0",
            "",
            "",
            "def main():",
            "\tglobal args, best_acc1",
            "\targs = parser.parse_args()",
            "",
            "\tif args.seed is not None:",
            "\t\trandom.seed(args.seed)",
            "\t\ttorch.manual_seed(args.seed)",
            "\t\tcudnn.deterministic = True",
            "\t\twarnings.warn('You have chosen to seed training. '",
            "\t\t\t\t\t  'This will turn on the CUDNN deterministic setting, '",
            "\t\t\t\t\t  'which can slow down your training considerably! '",
            "\t\t\t\t\t  'You may see unexpected behavior when restarting '",
            "\t\t\t\t\t  'from checkpoints.')",
            "",
            "\tif args.gpu is not None:",
            "\t\twarnings.warn('You have chosen a specific GPU. This will completely '",
            "\t\t\t\t\t  'disable data parallelism.')",
            "",
            "\targs.distributed = args.world_size > 1",
            "",
            "\tif args.distributed:",
            "\t\tdist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,",
            "\t\t\t\t\t\t\t\tworld_size=args.world_size)",
            "",
            "\t# create model",
            "\tif args.pretrained:",
            "\t\tprint(\"=> using pre-trained model '{}'\".format(args.arch))",
            "\t\tmodel = models.__dict__[args.arch](pretrained=True)",
            "\telse:",
            "\t\tprint(\"=> creating model '{}'\".format(args.arch))",
            "\t\tmodel = models.__dict__[args.arch]()",
            "",
            "\tif args.gpu is not None:",
            "\t\tmodel = model.cuda(args.gpu)",
            "\telif args.distributed:",
            "\t\tmodel.cuda()",
            "\t\tmodel = torch.nn.parallel.DistributedDataParallel(model)",
            "\telse:",
            "\t\tif args.arch.startswith('alexnet') or args.arch.startswith('vgg'):",
            "\t\t\tmodel.features = torch.nn.DataParallel(model.features)",
            "\t\t\tmodel.cuda()",
            "\t\telse:",
            "\t\t\tmodel = torch.nn.DataParallel(model).cuda()",
            "",
            "\t# define loss function (criterion) and optimizer",
            "\tcriterion = nn.CrossEntropyLoss().cuda(args.gpu)",
            "",
            "\toptimizer = torch.optim.SGD(model.parameters(), args.lr,",
            "\t\t\t\t\t\t\t\tmomentum=args.momentum,",
            "\t\t\t\t\t\t\t\tweight_decay=args.weight_decay)",
            "",
            "\t# optionally resume from a checkpoint",
            "\tif args.resume:",
            "\t\tif os.path.isfile(args.resume):",
            "\t\t\tprint(\"=> loading checkpoint '{}'\".format(args.resume))",
            "\t\t\tcheckpoint = torch.load(args.resume)",
            "\t\t\targs.start_epoch = checkpoint['epoch']",
            "\t\t\tbest_acc1 = checkpoint['best_acc1']",
            "\t\t\tmodel.load_state_dict(checkpoint['state_dict'])",
            "\t\t\toptimizer.load_state_dict(checkpoint['optimizer'])",
            "\t\t\tprint(\"=> loaded checkpoint '{}' (epoch {})\"",
            "\t\t\t\t  .format(args.resume, checkpoint['epoch']))",
            "\t\telse:",
            "\t\t\tprint(\"=> no checkpoint found at '{}'\".format(args.resume))",
            "",
            "\tcudnn.benchmark = True",
            "",
            "\t# Data loading code",
            "\ttraindir = os.path.join(args.data, 'train')",
            "\tvaldir = os.path.join(args.data, 'val')",
            "\tnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],",
            "\t\t\t\t\t\t\t\t     std=[0.229, 0.224, 0.225])",
            "",
            "\ttrain_dataset = datasets.ImageFolder(",
            "\t\ttraindir,",
            "\t\ttransforms.Compose([",
            "\t\t\ttransforms.RandomResizedCrop(224),",
            "\t\t\ttransforms.RandomHorizontalFlip(),",
            "\t\t\ttransforms.ToTensor(),",
            "\t\t\tnormalize,",
            "\t\t]))",
            "",
            "\tif args.distributed:",
            "\t\ttrain_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)",
            "\telse:",
            "\t\ttrain_sampler = None",
            "",
            "\ttrain_loader = torch.utils.data.DataLoader(",
            "\t\ttrain_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),",
            "\t\tnum_workers=args.workers, pin_memory=True, sampler=train_sampler)",
            "",
            "\tval_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.ImageFolder(valdir, transforms.Compose([",
            "\t\t\ttransforms.Resize(256),",
            "\t\t\ttransforms.CenterCrop(224),",
            "\t\t\ttransforms.ToTensor(),",
            "\t\t\tnormalize,",
            "\t\t])),",
            "\t\tbatch_size=args.batch_size, shuffle=False,",
            "\t\tnum_workers=args.workers, pin_memory=True)",
            "",
            "\tif args.evaluate:",
            "\t\tvalidate(val_loader, model, criterion)",
            "\t\treturn",
            "",
            "\tfor epoch in range(args.start_epoch, args.epochs):",
            "\t\tif args.distributed:",
            "\t\t\ttrain_sampler.set_epoch(epoch)",
            "\t\tadjust_learning_rate(optimizer, epoch)",
            "",
            "\t\t# train for one epoch",
            "\t\ttrain(train_loader, model, criterion, optimizer, epoch)",
            "",
            "\t\t# evaluate on validation set",
            "\t\tacc1 = validate(val_loader, model, criterion)",
            "",
            "\t\t# remember best acc@1 and save checkpoint",
            "\t\tis_best = acc1 > best_acc1",
            "\t\tbest_acc1 = max(acc1, best_acc1)",
            "\t\tsave_checkpoint({",
            "\t\t\t'epoch': epoch + 1,",
            "\t\t\t'arch': args.arch,",
            "\t\t\t'state_dict': model.state_dict(),",
            "\t\t\t'best_acc1': best_acc1,",
            "\t\t\t'optimizer' : optimizer.state_dict(),",
            "\t\t}, is_best)",
            "",
            "",
            "def train(train_loader, model, criterion, optimizer, epoch):",
            "\tbatch_time = AverageMeter()",
            "\tdata_time = AverageMeter()",
            "\tlosses = AverageMeter()",
            "\ttop1 = AverageMeter()",
            "\ttop5 = AverageMeter()",
            "",
            "\t# switch to train mode",
            "\tmodel.train()",
            "",
            "\tend = time.time()",
            "\tfor i, (input, target) in enumerate(train_loader):",
            "\t\t# measure data loading time",
            "\t\tdata_time.update(time.time() - end)",
            "",
            "\t\tif args.gpu is not None:",
            "\t\t\tinput = input.cuda(args.gpu, non_blocking=True)",
            "\t\ttarget = target.cuda(args.gpu, non_blocking=True)",
            "",
            "\t\t# compute output",
            "\t\toutput = model(input)",
            "\t\tloss = criterion(output, target)",
            "",
            "\t\t# measure accuracy and record loss",
            "\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))",
            "\t\tlosses.update(loss.item(), input.size(0))",
            "\t\ttop1.update(acc1[0], input.size(0))",
            "\t\ttop5.update(acc5[0], input.size(0))",
            "",
            "\t\t# compute gradient and do SGD step",
            "\t\toptimizer.zero_grad()",
            "\t\tloss.backward()",
            "\t\toptimizer.step()",
            "",
            "\t\t# measure elapsed time",
            "\t\tbatch_time.update(time.time() - end)",
            "\t\tend = time.time()",
            "",
            "\t\tif i % args.print_freq == 0:",
            "\t\t\tprint('Epoch: [{0}][{1}/{2}]\\t'",
            "\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'",
            "\t\t\t\t  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'",
            "\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'",
            "\t\t\t\t  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'",
            "\t\t\t\t  'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(",
            "\t\t\t\t   epoch, i, len(train_loader), batch_time=batch_time,",
            "\t\t\t\t   data_time=data_time, loss=losses, top1=top1, top5=top5))",
            "",
            "",
            "def validate(val_loader, model, criterion):",
            "\tbatch_time = AverageMeter()",
            "\tlosses = AverageMeter()",
            "\ttop1 = AverageMeter()",
            "\ttop5 = AverageMeter()",
            "",
            "\t# switch to evaluate mode",
            "\tmodel.eval()",
            "",
            "\twith torch.no_grad():",
            "\t\tend = time.time()",
            "\t\tfor i, (input, target) in enumerate(val_loader):",
            "\t\t\tif args.gpu is not None:",
            "\t\t\t\tinput = input.cuda(args.gpu, non_blocking=True)",
            "\t\t\ttarget = target.cuda(args.gpu, non_blocking=True)",
            "",
            "\t\t\t# compute output",
            "\t\t\toutput = model(input)",
            "\t\t\tloss = criterion(output, target)",
            "",
            "\t\t\t# measure accuracy and record loss",
            "\t\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))",
            "\t\t\tlosses.update(loss.item(), input.size(0))",
            "\t\t\ttop1.update(acc1[0], input.size(0))",
            "\t\t\ttop5.update(acc5[0], input.size(0))",
            "",
            "\t\t\t# measure elapsed time",
            "\t\t\tbatch_time.update(time.time() - end)",
            "\t\t\tend = time.time()",
            "",
            "\t\t\tif i % args.print_freq == 0:",
            "\t\t\t\tprint('Test: [{0}/{1}]\\t'",
            "\t\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'",
            "\t\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'",
            "\t\t\t\t\t  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'",
            "\t\t\t\t\t  'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(",
            "\t\t\t\t\t   i, len(val_loader), batch_time=batch_time, loss=losses,",
            "\t\t\t\t\t   top1=top1, top5=top5))",
            "",
            "\t\tprint(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'",
            "\t\t\t  .format(top1=top1, top5=top5))",
            "",
            "\treturn top1.avg",
            "",
            "",
            "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):",
            "\ttorch.save(state, filename)",
            "\tif is_best:",
            "\t\tshutil.copyfile(filename, 'model_best.pth.tar')",
            "",
            "",
            "class AverageMeter(object):",
            "\t\"\"\"Computes and stores the average and current value\"\"\"",
            "\tdef __init__(self):",
            "\t\tself.reset()",
            "",
            "\tdef reset(self):",
            "\t\tself.val = 0",
            "\t\tself.avg = 0",
            "\t\tself.sum = 0",
            "\t\tself.count = 0",
            "",
            "\tdef update(self, val, n=1):",
            "\t\tself.val = val",
            "\t\tself.sum += val * n",
            "\t\tself.count += n",
            "\t\tself.avg = self.sum / self.count",
            "",
            "",
            "def adjust_learning_rate(optimizer, epoch):",
            "\t\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"",
            "\tlr = args.lr * (0.1 ** (epoch // 30))",
            "\tfor param_group in optimizer.param_groups:",
            "\t\tparam_group['lr'] = lr",
            "",
            "",
            "def accuracy(output, target, topk=(1,)):",
            "\t\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"",
            "\twith torch.no_grad():",
            "\t\tmaxk = max(topk)",
            "\t\tbatch_size = target.size(0)",
            "",
            "\t\t_, pred = output.topk(maxk, 1, True, True)",
            "\t\tpred = pred.t()",
            "\t\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))",
            "",
            "\t\tres = []",
            "\t\tfor k in topk:",
            "\t\t\tcorrect_k = correct[:k].view(-1).float().sum(0, keepdim=True)",
            "\t\t\tres.append(correct_k.mul_(100.0 / batch_size))",
            "\t\treturn res",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "Mnist Example": {
        "prefix": "pytorch:examples:mnist",
        "description": "Mnist code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torchvision import datasets, transforms",
            "",
            "class Net(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Net, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)",
            "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)",
            "\t\tself.conv2_drop = nn.Dropout2d()",
            "\t\tself.fc1 = nn.Linear(320, 50)",
            "\t\tself.fc2 = nn.Linear(50, 10)",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(F.max_pool2d(self.conv1(x), 2))",
            "\t\tx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))",
            "\t\tx = x.view(-1, 320)",
            "\t\tx = F.relu(self.fc1(x))",
            "\t\tx = F.dropout(x, training=self.training)",
            "\t\tx = self.fc2(x)",
            "\t\treturn F.log_softmax(x, dim=1)",
            "",
            "def train(args, model, device, train_loader, optimizer, epoch):",
            "\tmodel.train()",
            "\tfor batch_idx, (data, target) in enumerate(train_loader):",
            "\t\tdata, target = data.to(device), target.to(device)",
            "\t\toptimizer.zero_grad()",
            "\t\toutput = model(data)",
            "\t\tloss = F.nll_loss(output, target)",
            "\t\tloss.backward()",
            "\t\toptimizer.step()",
            "\t\tif batch_idx % args.log_interval == 0:",
            "\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(",
            "\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),",
            "\t\t\t\t100. * batch_idx / len(train_loader), loss.item()))",
            "",
            "def test(args, model, device, test_loader):",
            "\tmodel.eval()",
            "\ttest_loss = 0",
            "\tcorrect = 0",
            "\twith torch.no_grad():",
            "\t\tfor data, target in test_loader:",
            "\t\t\tdata, target = data.to(device), target.to(device)",
            "\t\t\toutput = model(data)",
            "\t\t\ttest_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss",
            "\t\t\tpred = output.max(1, keepdim=True)[1] # get the index of the max log-probability",
            "\t\t\tcorrect += pred.eq(target.view_as(pred)).sum().item()",
            "",
            "\ttest_loss /= len(test_loader.dataset)",
            "\tprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(",
            "\t\ttest_loss, correct, len(test_loader.dataset),",
            "\t\t100. * correct / len(test_loader.dataset)))",
            "",
            "def main():",
            "\t# Training settings",
            "\tparser = argparse.ArgumentParser(description='PyTorch MNIST Example')",
            "\tparser.add_argument('--batch-size', type=int, default=64, metavar='N',",
            "\t\t\t\t\t\thelp='input batch size for training (default: 64)')",
            "\tparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',",
            "\t\t\t\t\t\thelp='input batch size for testing (default: 1000)')",
            "\tparser.add_argument('--epochs', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "\tparser.add_argument('--lr', type=float, default=0.01, metavar='LR',",
            "\t\t\t\t\t\thelp='learning rate (default: 0.01)')",
            "\tparser.add_argument('--momentum', type=float, default=0.5, metavar='M',",
            "\t\t\t\t\t\thelp='SGD momentum (default: 0.5)')",
            "\tparser.add_argument('--no-cuda', action='store_true', default=False,",
            "\t\t\t\t\t\thelp='disables CUDA training')",
            "\tparser.add_argument('--seed', type=int, default=1, metavar='S',",
            "\t\t\t\t\t\thelp='random seed (default: 1)')",
            "\tparser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "\targs = parser.parse_args()",
            "\tuse_cuda = not args.no_cuda and torch.cuda.is_available()",
            "",
            "\ttorch.manual_seed(args.seed)",
            "",
            "\tdevice = torch.device(\"cuda\" if use_cuda else \"cpu\")",
            "",
            "\tkwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}",
            "\ttrain_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.MNIST('../data', train=True, download=True,",
            "\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t   transforms.Normalize((0.1307,), (0.3081,))",
            "\t\t\t\t\t   ])),",
            "\t\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "\ttest_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.MNIST('../data', train=False, transform=transforms.Compose([",
            "\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t   transforms.Normalize((0.1307,), (0.3081,))",
            "\t\t\t\t\t   ])),",
            "\t\tbatch_size=args.test_batch_size, shuffle=True, **kwargs)",
            "",
            "",
            "\tmodel = Net().to(device)",
            "\toptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)",
            "",
            "\tfor epoch in range(1, args.epochs + 1):",
            "\t\ttrain(args, model, device, train_loader, optimizer, epoch)",
            "\t\ttest(args, model, device, test_loader)",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "RL Example VPG": {
        "prefix": "pytorch:examples:vpg",
        "description": "VPG code example",
        "body": [
            "import argparse",
            "import gym",
            "import numpy as np",
            "from itertools import count",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')",
            "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "parser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\thelp='random seed (default: 543)')",
            "parser.add_argument('--render', action='store_true',",
            "\t\t\t\t\thelp='render the environment')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "args = parser.parse_args()",
            "",
            "",
            "env = gym.make('CartPole-v0')",
            "env.seed(args.seed)",
            "torch.manual_seed(args.seed)",
            "",
            "",
            "class Policy(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "\t\tself.affine2 = nn.Linear(128, 2)",
            "",
            "\t\tself.saved_log_probs = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(self.affine1(x))",
            "\t\taction_scores = self.affine2(x)",
            "\t\treturn F.softmax(action_scores, dim=1)",
            "",
            "",
            "policy = Policy()",
            "optimizer = optim.Adam(policy.parameters(), lr=1e-2)",
            "eps = np.finfo(np.float32).eps.item()",
            "",
            "",
            "def select_action(state):",
            "\tstate = torch.from_numpy(state).float().unsqueeze(0)",
            "\tprobs = policy(state)",
            "\tm = Categorical(probs)",
            "\taction = m.sample()",
            "\tpolicy.saved_log_probs.append(m.log_prob(action))",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode():",
            "\tR = 0",
            "\tpolicy_loss = []",
            "\trewards = []",
            "\tfor r in policy.rewards[::-1]:",
            "\t\tR = r + args.gamma * R",
            "\t\trewards.insert(0, R)",
            "\trewards = torch.tensor(rewards)",
            "\trewards = (rewards - rewards.mean()) / (rewards.std() + eps)",
            "\tfor log_prob, reward in zip(policy.saved_log_probs, rewards):",
            "\t\tpolicy_loss.append(-log_prob * reward)",
            "\toptimizer.zero_grad()",
            "\tpolicy_loss = torch.cat(policy_loss).sum()",
            "\tpolicy_loss.backward()",
            "\toptimizer.step()",
            "\tdel policy.rewards[:]",
            "\tdel policy.saved_log_probs[:]",
            "",
            "",
            "def main():",
            "\trunning_reward = 10",
            "\tfor i_episode in count(1):",
            "\t\tstate = env.reset()",
            "\t\tfor t in range(10000):  # Don't infinite loop while learning",
            "\t\t\taction = select_action(state)",
            "\t\t\tstate, reward, done, _ = env.step(action)",
            "\t\t\tif args.render:",
            "\t\t\t\tenv.render()",
            "\t\t\tpolicy.rewards.append(reward)",
            "\t\t\tif done:",
            "\t\t\t\tbreak",
            "",
            "\t\trunning_reward = running_reward * 0.99 + t * 0.01",
            "\t\tfinish_episode()",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(",
            "\t\t\t\ti_episode, t, running_reward))",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, t))",
            "\t\t\tbreak",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "RL Example Actor-Critic": {
        "prefix": "pytorch:examples:ac",
        "description": "Actor-Critic code example",
        "body": [
            "import argparse",
            "import gym",
            "import numpy as np",
            "from itertools import count",
            "from collections import namedtuple",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch actor-critic example')",
            "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "parser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\thelp='random seed (default: 1)')",
            "parser.add_argument('--render', action='store_true',",
            "\t\t\t\t\thelp='render the environment')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "args = parser.parse_args()",
            "",
            "",
            "env = gym.make('CartPole-v0')",
            "env.seed(args.seed)",
            "torch.manual_seed(args.seed)",
            "",
            "",
            "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])",
            "",
            "",
            "class Policy(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "\t\tself.action_head = nn.Linear(128, 2)",
            "\t\tself.value_head = nn.Linear(128, 1)",
            "",
            "\t\tself.saved_actions = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(self.affine1(x))",
            "\t\taction_scores = self.action_head(x)",
            "\t\tstate_values = self.value_head(x)",
            "\t\treturn F.softmax(action_scores, dim=-1), state_values",
            "",
            "",
            "model = Policy()",
            "optimizer = optim.Adam(model.parameters(), lr=3e-2)",
            "eps = np.finfo(np.float32).eps.item()",
            "",
            "",
            "def select_action(state):",
            "\tstate = torch.from_numpy(state).float()",
            "\tprobs, state_value = model(state)",
            "\tm = Categorical(probs)",
            "\taction = m.sample()",
            "\tmodel.saved_actions.append(SavedAction(m.log_prob(action), state_value))",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode():",
            "\tR = 0",
            "\tsaved_actions = model.saved_actions",
            "\tpolicy_losses = []",
            "\tvalue_losses = []",
            "\trewards = []",
            "\tfor r in model.rewards[::-1]:",
            "\t\tR = r + args.gamma * R",
            "\t\trewards.insert(0, R)",
            "\trewards = torch.tensor(rewards)",
            "\trewards = (rewards - rewards.mean()) / (rewards.std() + eps)",
            "\tfor (log_prob, value), r in zip(saved_actions, rewards):",
            "\t\treward = r - value.item()",
            "\t\tpolicy_losses.append(-log_prob * reward)",
            "\t\tvalue_losses.append(F.smooth_l1_loss(value, torch.tensor([r])))",
            "\toptimizer.zero_grad()",
            "\tloss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()",
            "\tloss.backward()",
            "\toptimizer.step()",
            "\tdel model.rewards[:]",
            "\tdel model.saved_actions[:]",
            "",
            "",
            "def main():",
            "\trunning_reward = 10",
            "\tfor i_episode in count(1):",
            "\t\tstate = env.reset()",
            "\t\tfor t in range(10000):  # Don't infinite loop while learning",
            "\t\t\taction = select_action(state)",
            "\t\t\tstate, reward, done, _ = env.step(action)",
            "\t\t\tif args.render:",
            "\t\t\t\tenv.render()",
            "\t\t\tmodel.rewards.append(reward)",
            "\t\t\tif done:",
            "\t\t\t\tbreak",
            "",
            "\t\trunning_reward = running_reward * 0.99 + t * 0.01",
            "\t\tfinish_episode()",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}'.format(",
            "\t\t\t\ti_episode, t, running_reward))",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, t))",
            "\t\t\tbreak",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "DCGAN Example": {
        "prefix": "pytorch:examples:dcgan",
        "description": "DCGAN code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import os",
            "import random",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.parallel",
            "import torch.backends.cudnn as cudnn",
            "import torch.optim as optim",
            "import torch.utils.data",
            "import torchvision.datasets as dset",
            "import torchvision.transforms as transforms",
            "import torchvision.utils as vutils",
            "",
            "",
            "parser = argparse.ArgumentParser()",
            "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw | fake')",
            "parser.add_argument('--dataroot', required=True, help='path to dataset')",
            "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)",
            "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')",
            "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')",
            "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')",
            "parser.add_argument('--ngf', type=int, default=64)",
            "parser.add_argument('--ndf', type=int, default=64)",
            "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')",
            "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')",
            "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')",
            "parser.add_argument('--cuda', action='store_true', help='enables cuda')",
            "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')",
            "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")",
            "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")",
            "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')",
            "parser.add_argument('--manualSeed', type=int, help='manual seed')",
            "",
            "opt = parser.parse_args()",
            "print(opt)",
            "",
            "try:",
            "\tos.makedirs(opt.outf)",
            "except OSError:",
            "\tpass",
            "",
            "if opt.manualSeed is None:",
            "\topt.manualSeed = random.randint(1, 10000)",
            "print(\"Random Seed: \", opt.manualSeed)",
            "random.seed(opt.manualSeed)",
            "torch.manual_seed(opt.manualSeed)",
            "",
            "cudnn.benchmark = True",
            "",
            "if torch.cuda.is_available() and not opt.cuda:",
            "\tprint(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")",
            "",
            "if opt.dataset in ['imagenet', 'folder', 'lfw']:",
            "\t# folder dataset",
            "\tdataset = dset.ImageFolder(root=opt.dataroot,",
            "\t\t\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t\t\t   transforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\t\t   transforms.CenterCrop(opt.imageSize),",
            "\t\t\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t\t\t   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t\t   ]))",
            "elif opt.dataset == 'lsun':",
            "\tdataset = dset.LSUN(root=opt.dataroot, classes=['bedroom_train'],",
            "\t\t\t\t\t\ttransform=transforms.Compose([",
            "\t\t\t\t\t\t\ttransforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\ttransforms.CenterCrop(opt.imageSize),",
            "\t\t\t\t\t\t\ttransforms.ToTensor(),",
            "\t\t\t\t\t\t\ttransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t]))",
            "elif opt.dataset == 'cifar10':",
            "\tdataset = dset.CIFAR10(root=opt.dataroot, download=True,",
            "\t\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t\t   transforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t\t   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t   ]))",
            "elif opt.dataset == 'fake':",
            "\tdataset = dset.FakeData(image_size=(3, opt.imageSize, opt.imageSize),",
            "\t\t\t\t\t\t\ttransform=transforms.ToTensor())",
            "assert dataset",
            "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,",
            "\t\t\t\t\t\t\t\t         shuffle=True, num_workers=int(opt.workers))",
            "",
            "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")",
            "ngpu = int(opt.ngpu)",
            "nz = int(opt.nz)",
            "ngf = int(opt.ngf)",
            "ndf = int(opt.ndf)",
            "nc = 3",
            "",
            "",
            "# custom weights initialization called on netG and netD",
            "def weights_init(m):",
            "\tclassname = m.__class__.__name__",
            "\tif classname.find('Conv') != -1:",
            "\t\tm.weight.data.normal_(0.0, 0.02)",
            "\telif classname.find('BatchNorm') != -1:",
            "\t\tm.weight.data.normal_(1.0, 0.02)",
            "\t\tm.bias.data.fill_(0)",
            "",
            "",
            "class Generator(nn.Module):",
            "\tdef __init__(self, ngpu):",
            "\t\tsuper(Generator, self).__init__()",
            "\t\tself.ngpu = ngpu",
            "\t\tself.main = nn.Sequential(",
            "\t\t\t# input is Z, going into a convolution",
            "\t\t\tnn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 8),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*8) x 4 x 4",
            "\t\t\tnn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 4),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*4) x 8 x 8",
            "\t\t\tnn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 2),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*2) x 16 x 16",
            "\t\t\tnn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf) x 32 x 32",
            "\t\t\tnn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),",
            "\t\t\tnn.Tanh()",
            "\t\t\t# state size. (nc) x 64 x 64",
            "\t\t)",
            "",
            "\tdef forward(self, input):",
            "\t\tif input.is_cuda and self.ngpu > 1:",
            "\t\t\toutput = nn.parallel.data_parallel(self.main, input, range(self.ngpu))",
            "\t\telse:",
            "\t\t\toutput = self.main(input)",
            "\t\treturn output",
            "",
            "",
            "netG = Generator(ngpu).to(device)",
            "netG.apply(weights_init)",
            "if opt.netG != '':",
            "\tnetG.load_state_dict(torch.load(opt.netG))",
            "print(netG)",
            "",
            "",
            "class Discriminator(nn.Module):",
            "\tdef __init__(self, ngpu):",
            "\t\tsuper(Discriminator, self).__init__()",
            "\t\tself.ngpu = ngpu",
            "\t\tself.main = nn.Sequential(",
            "\t\t\t# input is (nc) x 64 x 64",
            "\t\t\tnn.Conv2d(nc, ndf, 4, 2, 1, bias=False),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf) x 32 x 32",
            "\t\t\tnn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 2),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*2) x 16 x 16",
            "\t\t\tnn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 4),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*4) x 8 x 8",
            "\t\t\tnn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 8),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*8) x 4 x 4",
            "\t\t\tnn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),",
            "\t\t\tnn.Sigmoid()",
            "\t\t)",
            "",
            "\tdef forward(self, input):",
            "\t\tif input.is_cuda and self.ngpu > 1:",
            "\t\t\toutput = nn.parallel.data_parallel(self.main, input, range(self.ngpu))",
            "\t\telse:",
            "\t\t\toutput = self.main(input)",
            "",
            "\t\treturn output.view(-1, 1).squeeze(1)",
            "",
            "",
            "netD = Discriminator(ngpu).to(device)",
            "netD.apply(weights_init)",
            "if opt.netD != '':",
            "\tnetD.load_state_dict(torch.load(opt.netD))",
            "print(netD)",
            "",
            "criterion = nn.BCELoss()",
            "",
            "fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)",
            "real_label = 1",
            "fake_label = 0",
            "",
            "# setup optimizer",
            "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))",
            "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))",
            "",
            "for epoch in range(opt.niter):",
            "\tfor i, data in enumerate(dataloader, 0):",
            "\t\t############################",
            "\t\t# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))",
            "\t\t###########################",
            "\t\t# train with real",
            "\t\tnetD.zero_grad()",
            "\t\treal_cpu = data[0].to(device)",
            "\t\tbatch_size = real_cpu.size(0)",
            "\t\tlabel = torch.full((batch_size,), real_label, device=device)",
            "",
            "\t\toutput = netD(real_cpu)",
            "\t\terrD_real = criterion(output, label)",
            "\t\terrD_real.backward()",
            "\t\tD_x = output.mean().item()",
            "",
            "\t\t# train with fake",
            "\t\tnoise = torch.randn(batch_size, nz, 1, 1, device=device)",
            "\t\tfake = netG(noise)",
            "\t\tlabel.fill_(fake_label)",
            "\t\toutput = netD(fake.detach())",
            "\t\terrD_fake = criterion(output, label)",
            "\t\terrD_fake.backward()",
            "\t\tD_G_z1 = output.mean().item()",
            "\t\terrD = errD_real + errD_fake",
            "\t\toptimizerD.step()",
            "",
            "\t\t############################",
            "\t\t# (2) Update G network: maximize log(D(G(z)))",
            "\t\t###########################",
            "\t\tnetG.zero_grad()",
            "\t\tlabel.fill_(real_label)  # fake labels are real for generator cost",
            "\t\toutput = netD(fake)",
            "\t\terrG = criterion(output, label)",
            "\t\terrG.backward()",
            "\t\tD_G_z2 = output.mean().item()",
            "\t\toptimizerG.step()",
            "",
            "\t\tprint('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'",
            "\t\t\t  % (epoch, opt.niter, i, len(dataloader),",
            "\t\t\t\t errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))",
            "\t\tif i % 100 == 0:",
            "\t\t\tvutils.save_image(real_cpu,",
            "\t\t\t\t\t'%s/real_samples.png' % opt.outf,",
            "\t\t\t\t\tnormalize=True)",
            "\t\t\tfake = netG(fixed_noise)",
            "\t\t\tvutils.save_image(fake.detach(),",
            "\t\t\t\t\t'%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),",
            "\t\t\t\t\tnormalize=True)",
            "",
            "\t# do checkpointing",
            "\ttorch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))",
            "\ttorch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))"
        ]
    },
    "Variational Autoencoder Example": {
        "prefix": "pytorch:examples:vae",
        "description": "Variational autoencoder code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import torch",
            "import torch.utils.data",
            "from torch import nn, optim",
            "from torch.nn import functional as F",
            "from torchvision import datasets, transforms",
            "from torchvision.utils import save_image",
            "",
            "",
            "parser = argparse.ArgumentParser(description='VAE MNIST Example')",
            "parser.add_argument('--batch-size', type=int, default=128, metavar='N',",
            "\t\t\t\t\thelp='input batch size for training (default: 128)')",
            "parser.add_argument('--epochs', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "parser.add_argument('--no-cuda', action='store_true', default=False,",
            "\t\t\t\t\thelp='enables CUDA training')",
            "parser.add_argument('--seed', type=int, default=1, metavar='S',",
            "\t\t\t\t\thelp='random seed (default: 1)')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "args = parser.parse_args()",
            "args.cuda = not args.no_cuda and torch.cuda.is_available()",
            "",
            "torch.manual_seed(args.seed)",
            "",
            "device = torch.device(\"cuda\" if args.cuda else \"cpu\")",
            "",
            "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}",
            "train_loader = torch.utils.data.DataLoader(",
            "\tdatasets.MNIST('../data', train=True, download=True,",
            "\t\t\t\t   transform=transforms.ToTensor()),",
            "\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "test_loader = torch.utils.data.DataLoader(",
            "\tdatasets.MNIST('../data', train=False, transform=transforms.ToTensor()),",
            "\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "",
            "",
            "class VAE(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(VAE, self).__init__()",
            "",
            "\t\tself.fc1 = nn.Linear(784, 400)",
            "\t\tself.fc21 = nn.Linear(400, 20)",
            "\t\tself.fc22 = nn.Linear(400, 20)",
            "\t\tself.fc3 = nn.Linear(20, 400)",
            "\t\tself.fc4 = nn.Linear(400, 784)",
            "",
            "\tdef encode(self, x):",
            "\t\th1 = F.relu(self.fc1(x))",
            "\t\treturn self.fc21(h1), self.fc22(h1)",
            "",
            "\tdef reparameterize(self, mu, logvar):",
            "\t\tstd = torch.exp(0.5*logvar)",
            "\t\teps = torch.randn_like(std)",
            "\t\treturn eps.mul(std).add_(mu)",
            "",
            "\tdef decode(self, z):",
            "\t\th3 = F.relu(self.fc3(z))",
            "\t\treturn torch.sigmoid(self.fc4(h3))",
            "",
            "\tdef forward(self, x):",
            "\t\tmu, logvar = self.encode(x.view(-1, 784))",
            "\t\tz = self.reparameterize(mu, logvar)",
            "\t\treturn self.decode(z), mu, logvar",
            "",
            "",
            "model = VAE().to(device)",
            "optimizer = optim.Adam(model.parameters(), lr=1e-3)",
            "",
            "",
            "# Reconstruction + KL divergence losses summed over all elements and batch",
            "def loss_function(recon_x, x, mu, logvar):",
            "\tBCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')",
            "",
            "\t# see Appendix B from VAE paper:",
            "\t# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014",
            "\t# https://arxiv.org/abs/1312.6114",
            "\t# 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)",
            "\tKLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())",
            "",
            "\treturn BCE + KLD",
            "",
            "",
            "def train(epoch):",
            "\tmodel.train()",
            "\ttrain_loss = 0",
            "\tfor batch_idx, (data, _) in enumerate(train_loader):",
            "\t\tdata = data.to(device)",
            "\t\toptimizer.zero_grad()",
            "\t\trecon_batch, mu, logvar = model(data)",
            "\t\tloss = loss_function(recon_batch, data, mu, logvar)",
            "\t\tloss.backward()",
            "\t\ttrain_loss += loss.item()",
            "\t\toptimizer.step()",
            "\t\tif batch_idx % args.log_interval == 0:",
            "\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(",
            "\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),",
            "\t\t\t\t100. * batch_idx / len(train_loader),",
            "\t\t\t\tloss.item() / len(data)))",
            "",
            "\tprint('====> Epoch: {} Average loss: {:.4f}'.format(",
            "\t\t  epoch, train_loss / len(train_loader.dataset)))",
            "",
            "",
            "def test(epoch):",
            "\tmodel.eval()",
            "\ttest_loss = 0",
            "\twith torch.no_grad():",
            "\t\tfor i, (data, _) in enumerate(test_loader):",
            "\t\t\tdata = data.to(device)",
            "\t\t\trecon_batch, mu, logvar = model(data)",
            "\t\t\ttest_loss += loss_function(recon_batch, data, mu, logvar).item()",
            "\t\t\tif i == 0:",
            "\t\t\t\tn = min(data.size(0), 8)",
            "\t\t\t\tcomparison = torch.cat([data[:n],",
            "\t\t\t\t\t\t\t\t      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])",
            "\t\t\t\tsave_image(comparison.cpu(),",
            "\t\t\t\t\t\t 'results/reconstruction_' + str(epoch) + '.png', nrow=n)",
            "",
            "\ttest_loss /= len(test_loader.dataset)",
            "\tprint('====> Test set loss: {:.4f}'.format(test_loss))",
            "",
            "if __name__ == \"__main__\":",
            "\tfor epoch in range(1, args.epochs + 1):",
            "\t\ttrain(epoch)",
            "\t\ttest(epoch)",
            "\t\twith torch.no_grad():",
            "\t\t\tsample = torch.randn(64, 20).to(device)",
            "\t\t\tsample = model.decode(sample).cpu()",
            "\t\t\tsave_image(sample.view(64, 1, 28, 28),",
            "\t\t\t\t\t   'results/sample_' + str(epoch) + '.png')"
        ]
    }
}